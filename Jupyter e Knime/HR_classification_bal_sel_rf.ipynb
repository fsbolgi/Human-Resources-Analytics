{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from numpy.random import randint \n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>salary</th>\n",
       "      <th>average_daily_hours</th>\n",
       "      <th>time_spent_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>departments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>7.302326</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>12.186047</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>12.651163</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>10.372093</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>7.395349</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  left  \\\n",
       "0                0.38             0.53               2     1   \n",
       "1                0.80             0.86               5     1   \n",
       "2                0.11             0.88               7     1   \n",
       "3                0.72             0.87               5     1   \n",
       "4                0.37             0.52               2     1   \n",
       "\n",
       "   promotion_last_5years  salary  average_daily_hours  time_spent_company  \\\n",
       "0                      0     low             7.302326                   3   \n",
       "1                      0  medium            12.186047                   6   \n",
       "2                      0  medium            12.651163                   4   \n",
       "3                      0     low            10.372093                   5   \n",
       "4                      0     low             7.395349                   3   \n",
       "\n",
       "   work_accident departments  \n",
       "0              0       sales  \n",
       "1              0       sales  \n",
       "2              0       sales  \n",
       "3              0       sales  \n",
       "4              0       sales  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creazione di average_daily_hours, time_spenT_company, work_accident e departments\n",
    "df = pd.read_csv(\"HR_comma_sep.csv\")\n",
    "df['average_daily_hours']=df['average_montly_hours']/21.5\n",
    "df=df.drop(['average_montly_hours'], axis=1)\n",
    "\n",
    "df ['time_spent_company'] = df['time_spend_company']\n",
    "df=df.drop(['time_spend_company'], axis=1)\n",
    "\n",
    "df ['work_accident'] = df['Work_accident']\n",
    "df=df.drop(['Work_accident'], axis=1)\n",
    "\n",
    "df ['departments'] = df['sales']\n",
    "df=df.drop(['sales'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>salary</th>\n",
       "      <th>average_daily_hours</th>\n",
       "      <th>time_spent_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>departments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>7.302326</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>12.186047</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>12.651163</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>10.372093</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>7.395349</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  left  \\\n",
       "0                0.38             0.53               2     1   \n",
       "1                0.80             0.86               5     1   \n",
       "2                0.11             0.88               7     1   \n",
       "3                0.72             0.87               5     1   \n",
       "4                0.37             0.52               2     1   \n",
       "\n",
       "   promotion_last_5years  salary  average_daily_hours  time_spent_company  \\\n",
       "0                      0     low             7.302326                   3   \n",
       "1                      0  medium            12.186047                   6   \n",
       "2                      0  medium            12.651163                   4   \n",
       "3                      0     low            10.372093                   5   \n",
       "4                      0     low             7.395349                   3   \n",
       "\n",
       "   work_accident departments  \n",
       "0              0       sales  \n",
       "1              0       sales  \n",
       "2              0       sales  \n",
       "3              0       sales  \n",
       "4              0       sales  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creazione di average_daily_hours, time_spenT_company, work_accident e departments\n",
    "df = pd.read_csv(\"HR_comma_sep.csv\")\n",
    "df['average_daily_hours']=df['average_montly_hours']/21.5\n",
    "df=df.drop(['average_montly_hours'], axis=1)\n",
    "\n",
    "df ['time_spent_company'] = df['time_spend_company']\n",
    "df=df.drop(['time_spend_company'], axis=1)\n",
    "\n",
    "df ['work_accident'] = df['Work_accident']\n",
    "df=df.drop(['Work_accident'], axis=1)\n",
    "\n",
    "df ['departments'] = df['sales']\n",
    "df=df.drop(['sales'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funzione per trasformare le variabile categoriche in numeriche dumpy/binarie (sklearn.DecisionTree funziona solo con numeri e fa solo due split per nodo)\n",
    "def clean_data(df):\n",
    "    # Get the unique values of departments\n",
    "    departments_locs = sorted(df['departments'].unique())\n",
    "\n",
    "    # Generate a mapping of departments from a string to a number representation        \n",
    "    departments_locs_mapping = dict(zip(departments_locs, \n",
    "                                     range(0, len(departments_locs) + 1)))\n",
    "    \n",
    "    # Transform departments from a string to a number representation\n",
    "    df['departments_val'] = df['departments'].map(departments_locs_mapping).astype(int)\n",
    "    \n",
    "    # Transform departments from a string to dummy variables\n",
    "    df = pd.concat([df, pd.get_dummies(df['departments'], prefix='departments_val')], axis=1)\n",
    "    \n",
    "    # drop departments and departments_val\n",
    "    df=df.drop(['departments'], axis=1)\n",
    "    df=df.drop(['departments_val'], axis=1)\n",
    "    \n",
    "    \n",
    "     # Get the unique values of salary\n",
    "    salary_locs = sorted(df['salary'].unique())\n",
    "\n",
    "    # Generate a mapping of salary from a string to a number representation        \n",
    "    salary_locs_mapping = dict(zip(salary_locs, [2, 0, 1]))\n",
    "    \n",
    "    # Transform salary from a string to a number representation\n",
    "    df['salary_val'] = df['salary'].map(salary_locs_mapping).astype(int)\n",
    "    \n",
    "    # Transform salary from a string to dummy variables\n",
    "    df = pd.concat([df, pd.get_dummies(df['salary'], prefix='salary_val')], axis=1)\n",
    "    \n",
    "    # drop salary and salary_val\n",
    "    df=df.drop(['salary'], axis=1)\n",
    "    df=df.drop(['salary_val'], axis=1)\n",
    "    return df\n",
    "df= clean_data (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>average_daily_hours</th>\n",
       "      <th>time_spent_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>salary_val_high</th>\n",
       "      <th>salary_val_low</th>\n",
       "      <th>salary_val_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.302326</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.186047</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.651163</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.372093</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.395349</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  left  \\\n",
       "0                0.38             0.53               2     1   \n",
       "1                0.80             0.86               5     1   \n",
       "2                0.11             0.88               7     1   \n",
       "3                0.72             0.87               5     1   \n",
       "4                0.37             0.52               2     1   \n",
       "\n",
       "   promotion_last_5years  average_daily_hours  time_spent_company  \\\n",
       "0                      0             7.302326                   3   \n",
       "1                      0            12.186047                   6   \n",
       "2                      0            12.651163                   4   \n",
       "3                      0            10.372093                   5   \n",
       "4                      0             7.395349                   3   \n",
       "\n",
       "   work_accident  salary_val_high  salary_val_low  salary_val_medium  \n",
       "0              0                0               1                  0  \n",
       "1              0                0               0                  1  \n",
       "2              0                0               0                  1  \n",
       "3              0                0               1                  0  \n",
       "4              0                0               1                  0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creazione di un nuovo dataset da cui vengono eliminate alcune variabili che potrebbero non avere importanza nella classificazione\n",
    "df_selected_feat=df.drop(['departments_val_IT', 'departments_val_RandD', 'departments_val_accounting','departments_val_hr', 'departments_val_management',      \n",
    "'departments_val_marketing',        \n",
    "'departments_val_product_mng',     \n",
    "'departments_val_sales',          \n",
    "'departments_val_support',          \n",
    "'departments_val_technical'],axis=1)\n",
    "df_selected_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95        0.81        5.          0.          5.58139535  3.          0.\n",
      "  0.          1.          0.        ]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#divisione di df_selected_features in training e test\n",
    "# conversione del DataFrame in un numpy array:\n",
    "train_data_sel = df_selected_feat.values\n",
    "\n",
    "# selezione delle features senza la colonna left (target)\n",
    "train_sel_features = np.delete(train_data_sel,np.s_[3:4], axis=1)\n",
    "\n",
    "# selezione del target left\n",
    "train_sel_target = np.delete(train_data_sel,np.s_[0:3], axis=1)\n",
    "train_sel_target = train_sel_target[:, 0]\n",
    "\n",
    "train_sel_x, test_sel_x, train_sel_y, test_sel_y = train_test_split(train_sel_features, \n",
    "                                                    train_sel_target, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=0)\n",
    "\n",
    "\n",
    "# DATASET BILANCIATO con random under-sampling: le classi sono bilanciate, infatti ci sono 3571 left e 3571 non left per un totale di 7142 record\n",
    "train_sel_features_res, train_sel_target_res= RandomUnderSampler(ratio='majority', random_state=0).fit_sample(train_sel_features, train_sel_target)\n",
    "\n",
    "# divisione del DATASET BILANCIATO in training e in test - tecnica holdout->1/3 per test set(train_res_x e test_res_x formano insieme tutto il dataset mentre train_res_y e test_res_y corrispondono al target)\n",
    "train_sel_res_x, test_sel_res_x, train_sel_res_y, test_sel_res_y = train_test_split(train_sel_features_res, \n",
    "                                                    train_sel_target_res, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=0)\n",
    "\n",
    "print(train_sel_features_res[100])\n",
    "print (train_sel_target_res[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=30)\n",
    "param_grid = {\"criterion\":[\"gini\",\"entropy\"],\n",
    "              \"max_features\":range(1,11),\n",
    "              \"max_depth\": [2,3,4,5,6,7,8,9,10,11,12,None],\n",
    "              \"min_samples_split\": range(10, 431),\n",
    "              \"bootstrap\": [True]\n",
    "             }\n",
    "              \n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(clf, param_distributions=param_grid, scoring=make_scorer(accuracy_score), n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'criterion': ['gini', 'entropy'], 'max_features': range(1, 11), 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, None], 'min_samples_split': range(10, 431), 'bootstrap': [True]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=make_scorer(accuracy_score),\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(train_sel_features_res, train_sel_target_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.961 (std: 0.001)\n",
      "Parameters: {'min_samples_split': 32, 'max_features': 6, 'max_depth': 11, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.960 (std: 0.001)\n",
      "Parameters: {'min_samples_split': 78, 'max_features': 6, 'max_depth': 11, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.959 (std: 0.001)\n",
      "Parameters: {'min_samples_split': 42, 'max_features': 6, 'max_depth': 9, 'criterion': 'entropy', 'bootstrap': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(search.cv_results_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
       "            max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=32, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1713394782, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET BILANCIATO--->\n",
      "[  4.33260455e-01   5.88765319e-02   3.48536263e-02   2.45008869e-03\n",
      "   1.12786693e-01   3.57749925e-01   0.00000000e+00   0.00000000e+00\n",
      "   2.26805298e-05   0.00000000e+00]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.966771159875\n",
      "Accuratezza sul test:\n",
      "0.952906236742\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.94      0.99      0.97      2400\n",
      "       left       0.99      0.94      0.97      2385\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.92      0.99      0.95      1171\n",
      "       left       0.99      0.91      0.95      1186\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.96648045  0.96358543  0.95098039  0.95798319  0.94257703  0.96638655\n",
      "  0.95098039  0.95938375  0.95658263  0.96218487]\n",
      "Accuratezza: 0.96 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.96311858  0.96701929  0.96686372  0.96499689  0.96499689  0.96437461\n",
      "  0.96406347  0.96639701  0.96375233  0.96437461]\n",
      "Accuratezza: 0.96 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.94692737  0.93837535  0.92436975  0.92997199  0.91876751  0.94397759\n",
      "  0.93557423  0.92997199  0.95238095  0.92997199]\n",
      "Recall: 0.94 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.93308434  0.9446173   0.94306161  0.94212819  0.94803983  0.94150591\n",
      "  0.94026136  0.93808339  0.9390168   0.93683883]\n",
      "Recall: 0.94 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.98546512  0.98820059  0.97633136  0.9851632   0.96470588  0.98826979\n",
      "  0.96531792  0.98809524  0.96045198  0.99401198]\n",
      "Precision: 0.98 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.99271523  0.98892508  0.99019928  0.98728399  0.98132045  0.98663189\n",
      "  0.98725907  0.99439314  0.98788871  0.99143892]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.96581197  0.96264368  0.94964029  0.95677233  0.94117647  0.96561605\n",
      "  0.95021337  0.95815296  0.95639944  0.96092619]\n",
      "F1: 0.96 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.96197658  0.96626353  0.96605578  0.96417768  0.9643931   0.96354084\n",
      "  0.96318725  0.96541787  0.96283299  0.96336586]\n",
      "F1: 0.96 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#prova dell'albero ottenuto \n",
    "clf = tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
    "            max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=32, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=1713394782, splitter='best')\n",
    "clf = clf.fit(train_sel_res_x, train_sel_res_y)\n",
    "print (\"DATASET BILANCIATO--->\")\n",
    "print (clf.feature_importances_)\n",
    "\n",
    "print(\"TRANING E TEST FORMATI CON HOLDOUT->\")\n",
    "train_sel_res_pred = clf.predict(train_sel_res_x)\n",
    "test_sel_res_pred = clf.predict(test_sel_res_x)\n",
    "# Accuratezza sul training e sul test\n",
    "print (\"Accuratezza sul training:\")\n",
    "print (metrics.accuracy_score(train_sel_res_y, train_sel_res_pred))\n",
    "print (\"Accuratezza sul test:\")\n",
    "print (metrics.accuracy_score(test_sel_res_y, test_sel_res_pred))\n",
    "# recall, precision, f1_measure su training e su test\n",
    "print (\"r, p, f1-score sul training:\")\n",
    "print(classification_report(train_sel_res_y, \n",
    "                            train_sel_res_pred, \n",
    "                            target_names=['Not left', 'left']))\n",
    "print (\"r, p, f1-score sul test:\")\n",
    "print(classification_report(test_sel_res_y, \n",
    "                            test_sel_res_pred, \n",
    "                            target_names=['Not left', 'left']))\n",
    "\n",
    "print(\"TRANING E TEST FORMATI CON CROSS-VALIDATION->\")\n",
    "\n",
    "scores = cross_validate(clf, \n",
    "                        train_sel_features_res, train_sel_target_res, scoring=['accuracy','recall','precision','f1'],\n",
    "                        cv=10, return_train_score=True)\n",
    "\n",
    "print (\"Accuratezza test:\")\n",
    "print(scores['test_accuracy'])\n",
    "print ('Accuratezza: %0.2f (+/- %0.2f)' % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2))\n",
    "print (\"Accuratezza training:\")\n",
    "print(scores['train_accuracy'])\n",
    "print ('Accuratezza: %0.2f (+/- %0.2f)' % (scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
    "print (\"Recall test:\")\n",
    "print(scores['test_recall'])\n",
    "print ('Recall: %0.2f (+/- %0.2f)' % (scores['test_recall'].mean(), scores['test_recall'].std() * 2))\n",
    "print (\"Recall training:\")\n",
    "print(scores['train_recall'])\n",
    "print ('Recall: %0.2f (+/- %0.2f)' % (scores['train_recall'].mean(), scores['train_recall'].std() * 2))\n",
    "print (\"Precision test:\")\n",
    "print(scores['test_precision'])\n",
    "print ('Precision: %0.2f (+/- %0.2f)' % (scores['test_precision'].mean(), scores['test_precision'].std() * 2))\n",
    "print (\"Precision training:\")\n",
    "print(scores['train_precision'])\n",
    "print ('Precision: %0.2f (+/- %0.2f)' % (scores['train_precision'].mean(), scores['train_precision'].std() * 2))\n",
    "print (\"f1 test:\")\n",
    "print(scores['test_f1'])\n",
    "print ('F1: %0.2f (+/- %0.2f)' % (scores['test_f1'].mean(), scores['test_f1'].std() * 2))\n",
    "print (\"f1 training:\")\n",
    "print(scores['train_f1'])\n",
    "print ('F1: %0.2f (+/- %0.2f)' % (scores['train_f1'].mean(), scores['train_f1'].std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth:\n",
      "2\n",
      "DATASET BILANCIATO--->\n",
      "[ 0.52819458  0.          0.          0.          0.          0.47180542\n",
      "  0.          0.          0.          0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.878996865204\n",
      "Accuratezza sul test:\n",
      "0.869325413661\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.93      0.82      0.87      2400\n",
      "       left       0.84      0.94      0.89      2385\n",
      "\n",
      "avg / total       0.88      0.88      0.88      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.90      0.82      0.86      1171\n",
      "       left       0.84      0.91      0.88      1186\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.87430168  0.88095238  0.86414566  0.87394958  0.8697479   0.88655462\n",
      "  0.8907563   0.88095238  0.86414566  0.87254902]\n",
      "Accuratezza: 0.88 (+/- 0.02)\n",
      "Accuratezza training:\n",
      "[ 0.87597261  0.87523335  0.87710019  0.8760112   0.87647791  0.87461108\n",
      "  0.87414437  0.87523335  0.87710019  0.87616677]\n",
      "Accuratezza: 0.88 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93296089  0.93557423  0.92156863  0.93557423  0.90756303  0.91876751\n",
      "  0.93557423  0.93837535  0.92997199  0.92156863]\n",
      "Recall: 0.93 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92717087  0.92688239  0.92843808  0.92688239  0.92999378  0.92874922\n",
      "  0.92688239  0.92657125  0.92750467  0.92843808]\n",
      "Recall: 0.93 (+/- 0.00)\n",
      "Precision test:\n",
      "[ 0.835       0.84343434  0.82663317  0.83291771  0.84375     0.86315789\n",
      "  0.85861183  0.84170854  0.82178218  0.83928571]\n",
      "Precision: 0.84 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.84105025  0.84010152  0.84198646  0.84128777  0.8400787   0.83801235\n",
      "  0.83844638  0.84029345  0.84256642  0.84056338]\n",
      "Precision: 0.84 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.88126649  0.88711819  0.87152318  0.88126649  0.87449393  0.89009498\n",
      "  0.89544236  0.88741722  0.87253614  0.87850467]\n",
      "F1: 0.88 (+/- 0.02)\n",
      "f1 training:\n",
      "[ 0.88201332  0.88136095  0.88310151  0.88201332  0.88275251  0.88105077\n",
      "  0.88044924  0.88132584  0.88299763  0.88231815]\n",
      "F1: 0.88 (+/- 0.00)\n",
      "Max_depth:\n",
      "3\n",
      "DATASET BILANCIATO--->\n",
      "[ 0.45276979  0.          0.02346092  0.          0.08492835  0.43884094\n",
      "  0.          0.          0.          0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.916823406479\n",
      "Accuratezza sul test:\n",
      "0.913449299958\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.95      0.88      0.91      2400\n",
      "       left       0.89      0.95      0.92      2385\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.93      0.89      0.91      1171\n",
      "       left       0.90      0.93      0.92      1186\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.92318436  0.92016807  0.90616246  0.92577031  0.91176471  0.91176471\n",
      "  0.93557423  0.90896359  0.91036415  0.90336134]\n",
      "Accuratezza: 0.92 (+/- 0.02)\n",
      "Accuratezza training:\n",
      "[ 0.91487706  0.91521469  0.91677038  0.91459241  0.9161481   0.9161481\n",
      "  0.91350342  0.91645924  0.91630367  0.91708152]\n",
      "Accuratezza: 0.92 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.95810056  0.93557423  0.93557423  0.95798319  0.93837535  0.92997199\n",
      "  0.95518207  0.94117647  0.95518207  0.92997199]\n",
      "Recall: 0.94 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.94211018  0.9446173   0.9446173   0.94212819  0.94430616  0.94523958\n",
      "  0.94243933  0.94399502  0.94243933  0.94523958]\n",
      "Recall: 0.94 (+/- 0.00)\n",
      "Precision test:\n",
      "[ 0.89556136  0.9076087   0.88359788  0.9         0.89095745  0.8972973\n",
      "  0.91913747  0.88421053  0.87660668  0.88297872]\n",
      "Precision: 0.89 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.89344746  0.89215398  0.89478338  0.89295193  0.89396171  0.89326669\n",
      "  0.89088235  0.89472132  0.89562389  0.89484536]\n",
      "Precision: 0.89 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.92577598  0.92137931  0.90884354  0.92808684  0.91405184  0.9133425\n",
      "  0.93681319  0.91180461  0.91420912  0.9058663 ]\n",
      "F1: 0.92 (+/- 0.02)\n",
      "f1 training:\n",
      "[ 0.91713377  0.91763639  0.91902528  0.91688115  0.91844455  0.91851852\n",
      "  0.91593589  0.91869796  0.91843542  0.9193524 ]\n",
      "F1: 0.92 (+/- 0.00)\n",
      "Max_depth:\n",
      "4\n",
      "DATASET BILANCIATO--->\n",
      "[ 0.41933966  0.08429456  0.00962215  0.          0.08547505  0.40126858\n",
      "  0.          0.          0.          0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.938349007315\n",
      "Accuratezza sul test:\n",
      "0.925328807807\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.95      0.93      0.94      2400\n",
      "       left       0.93      0.95      0.94      2385\n",
      "\n",
      "avg / total       0.94      0.94      0.94      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.92      0.93      0.92      1171\n",
      "       left       0.93      0.92      0.93      1186\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.94134078  0.93697479  0.92857143  0.94537815  0.92857143  0.93137255\n",
      "  0.93557423  0.92296919  0.92857143  0.92717087]\n",
      "Accuratezza: 0.93 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.93370682  0.93419415  0.93512757  0.93326073  0.93606098  0.93403858\n",
      "  0.93434972  0.93543871  0.93481643  0.93528314]\n",
      "Accuratezza: 0.93 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.95251397  0.92717087  0.93837535  0.96078431  0.93277311  0.92717087\n",
      "  0.94397759  0.93837535  0.94957983  0.92436975]\n",
      "Recall: 0.94 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.93899782  0.94181705  0.9405725   0.93808339  0.94150591  0.94088363\n",
      "  0.93995022  0.94337274  0.93932794  0.94212819]\n",
      "Recall: 0.94 (+/- 0.00)\n",
      "Precision test:\n",
      "[ 0.93169399  0.94571429  0.92032967  0.93206522  0.925       0.93502825\n",
      "  0.92837466  0.91032609  0.91129032  0.92957746]\n",
      "Precision: 0.93 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.92916538  0.92767392  0.93044014  0.92912173  0.9313635   0.9281768\n",
      "  0.92953846  0.92863706  0.93092815  0.92940454]\n",
      "Precision: 0.93 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.94198895  0.93635078  0.92926491  0.9462069   0.92887029  0.93108298\n",
      "  0.93611111  0.92413793  0.93004115  0.92696629]\n",
      "F1: 0.93 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.93405573  0.93469199  0.93547888  0.93358105  0.93640724  0.93448702\n",
      "  0.93471535  0.93594691  0.93510918  0.93572311]\n",
      "F1: 0.94 (+/- 0.00)\n",
      "Max_depth:\n",
      "5\n",
      "DATASET BILANCIATO--->\n",
      "[ 0.41820261  0.0931294   0.02039144  0.          0.07685547  0.39074858\n",
      "  0.0006725   0.          0.          0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.940438871473\n",
      "Accuratezza sul test:\n",
      "0.926601612219\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.95      0.93      0.94      2400\n",
      "       left       0.93      0.95      0.94      2385\n",
      "\n",
      "avg / total       0.94      0.94      0.94      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.93      0.93      0.93      1171\n",
      "       left       0.93      0.93      0.93      1186\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.94832402  0.93977591  0.93137255  0.94397759  0.93557423  0.93837535\n",
      "  0.94537815  0.93417367  0.92857143  0.93277311]\n",
      "Accuratezza: 0.94 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.94008715  0.9390168   0.93932794  0.93870566  0.94072806  0.9369944\n",
      "  0.94041693  0.93792782  0.93963908  0.93995022]\n",
      "Accuratezza: 0.94 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.96089385  0.93277311  0.93837535  0.95518207  0.93557423  0.94397759\n",
      "  0.95798319  0.94677871  0.95518207  0.93277311]\n",
      "Recall: 0.95 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.94553377  0.94586185  0.94648413  0.94399502  0.94368388  0.94555072\n",
      "  0.94586185  0.94523958  0.94399502  0.94492844]\n",
      "Recall: 0.95 (+/- 0.00)\n",
      "Precision test:\n",
      "[ 0.9373297   0.94602273  0.92541436  0.93424658  0.93557423  0.93351801\n",
      "  0.93442623  0.92349727  0.90691489  0.93277311]\n",
      "Precision: 0.93 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.93534483  0.93308778  0.93312883  0.9341133   0.93813795  0.92964209\n",
      "  0.93567251  0.93161607  0.93584207  0.93561306]\n",
      "Precision: 0.93 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.94896552  0.9393512   0.93184979  0.94459834  0.93557423  0.93871866\n",
      "  0.94605809  0.93499308  0.93042292  0.93277311]\n",
      "F1: 0.94 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.9404117   0.9394314   0.93975904  0.93902816  0.94090275  0.93752892\n",
      "  0.94073959  0.93837838  0.93990087  0.94024768]\n",
      "F1: 0.94 (+/- 0.00)\n",
      "Max_depth:\n",
      "6\n",
      "DATASET BILANCIATO--->\n",
      "[  4.56359370e-01   8.41112796e-02   4.42881539e-02   0.00000000e+00\n",
      "   4.34438258e-02   3.70235684e-01   3.24267132e-04   7.41481610e-04\n",
      "   0.00000000e+00   4.95937966e-04]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.956739811912\n",
      "Accuratezza sul test:\n",
      "0.946966482817\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.93      0.99      0.96      2400\n",
      "       left       0.98      0.93      0.96      2385\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.91      0.99      0.95      1171\n",
      "       left       0.98      0.91      0.95      1186\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza test:\n",
      "[ 0.95670391  0.95098039  0.95518207  0.95658263  0.94257703  0.96218487\n",
      "  0.95938375  0.94537815  0.95378151  0.96078431]\n",
      "Accuratezza: 0.95 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.95736072  0.95737399  0.95706285  0.95675171  0.95815184  0.95752956\n",
      "  0.95690728  0.9578407   0.95644057  0.95690728]\n",
      "Accuratezza: 0.96 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93854749  0.91596639  0.92156863  0.93557423  0.91036415  0.93837535\n",
      "  0.93277311  0.91596639  0.92717087  0.93837535]\n",
      "Recall: 0.93 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92966075  0.93372744  0.9293715   0.92874922  0.93777225  0.93123833\n",
      "  0.93030492  0.93061605  0.92874922  0.92906036]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.97391304  0.98493976  0.98798799  0.97660819  0.97305389  0.98529412\n",
      "  0.9852071   0.97321429  0.97928994  0.98240469]\n",
      "Precision: 0.98 (+/- 0.01)\n",
      "Precision training:\n",
      "[ 0.98418451  0.98007838  0.98386034  0.9838497   0.9776192   0.98292282\n",
      "  0.98258298  0.98420533  0.98320158  0.98385502]\n",
      "Precision: 0.98 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.95590327  0.94920174  0.95362319  0.95565093  0.9406657   0.96126255\n",
      "  0.95827338  0.94372294  0.95251799  0.95988539]\n",
      "F1: 0.95 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.95614597  0.95634162  0.95584     0.95550576  0.95728125  0.95638281\n",
      "  0.95572958  0.9566608   0.9552      0.95567291]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "7\n",
      "DATASET BILANCIATO--->\n",
      "[ 0.45271294  0.09369888  0.01878874  0.          0.04914558  0.38298684\n",
      "  0.          0.00063438  0.00203265  0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.960292580982\n",
      "Accuratezza sul test:\n",
      "0.950360627917\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.93      0.99      0.96      2400\n",
      "       left       0.99      0.93      0.96      2385\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.91      0.99      0.95      1171\n",
      "       left       0.99      0.91      0.95      1186\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.95670391  0.94817927  0.94957983  0.95798319  0.94537815  0.95938375\n",
      "  0.96498599  0.94957983  0.94537815  0.96078431]\n",
      "Accuratezza: 0.95 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.95922814  0.95846297  0.95939639  0.95752956  0.96266335  0.95924082\n",
      "  0.95877411  0.95924082  0.9578407   0.9598631 ]\n",
      "Accuratezza: 0.96 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.94413408  0.91036415  0.92156863  0.92156863  0.91876751  0.92997199\n",
      "  0.93557423  0.92156863  0.93277311  0.92997199]\n",
      "Recall: 0.93 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92779334  0.93434972  0.93030492  0.92688239  0.94150591  0.92719353\n",
      "  0.92843808  0.93092719  0.93217175  0.92750467]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.96848138  0.98484848  0.97626113  0.9939577   0.9704142   0.98809524\n",
      "  0.99404762  0.97626113  0.95689655  0.99104478]\n",
      "Precision: 0.98 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.99003653  0.98169336  0.98777668  0.98740471  0.98310591  0.99069149\n",
      "  0.98840676  0.98680739  0.98261725  0.9916833 ]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.95615276  0.94614265  0.9481268   0.95639535  0.94388489  0.95815296\n",
      "  0.96392496  0.9481268   0.94468085  0.95953757]\n",
      "F1: 0.95 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.95790488  0.95743663  0.95817978  0.95618681  0.96185633  0.95789135\n",
      "  0.95748436  0.95805315  0.95673     0.9585209 ]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "8\n",
      "DATASET BILANCIATO--->\n",
      "[ 0.45738102  0.03763774  0.01486954  0.          0.08311166  0.40613036\n",
      "  0.          0.          0.00086967  0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.963636363636\n",
      "Accuratezza sul test:\n",
      "0.952057700467\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.94      0.99      0.96      2400\n",
      "       left       0.99      0.94      0.96      2385\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.92      0.99      0.95      1171\n",
      "       left       0.99      0.92      0.95      1186\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.96368715  0.94817927  0.94677871  0.96218487  0.95098039  0.96358543\n",
      "  0.96498599  0.94957983  0.94817927  0.96078431]\n",
      "Accuratezza: 0.96 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.9589169   0.96126322  0.96032981  0.95846297  0.96421904  0.96204107\n",
      "  0.96064095  0.96079652  0.96095208  0.95861854]\n",
      "Accuratezza: 0.96 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93854749  0.91316527  0.91316527  0.93277311  0.92436975  0.93557423\n",
      "  0.94397759  0.91596639  0.92436975  0.93277311]\n",
      "Recall: 0.93 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92530345  0.9334163   0.934972    0.92812694  0.94337274  0.934972\n",
      "  0.93154947  0.92968264  0.93808339  0.92501556]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.98823529  0.98192771  0.97897898  0.99107143  0.97633136  0.99109792\n",
      "  0.98538012  0.98198198  0.97058824  0.98813056]\n",
      "Precision: 0.98 (+/- 0.01)\n",
      "Precision training:\n",
      "[ 0.99199199  0.98846787  0.98492298  0.98807552  0.98441558  0.98848684\n",
      "  0.98909812  0.99137359  0.98304532  0.99166111]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.96275072  0.94629898  0.94492754  0.96103896  0.94964029  0.96253602\n",
      "  0.96423462  0.94782609  0.94691535  0.95965418]\n",
      "F1: 0.95 (+/- 0.02)\n",
      "f1 training:\n",
      "[ 0.95748792  0.96015362  0.95929769  0.95716348  0.96345726  0.96098497\n",
      "  0.95946162  0.95953757  0.96003821  0.95717965]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "9\n",
      "DATASET BILANCIATO--->\n",
      "[  4.41680544e-01   9.59608015e-02   2.99249545e-02   0.00000000e+00\n",
      "   7.37211061e-02   3.57700003e-01   0.00000000e+00   6.26345540e-04\n",
      "   3.43728186e-04   4.25170152e-05]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.963636363636\n",
      "Accuratezza sul test:\n",
      "0.949512091642\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.94      1.00      0.96      2400\n",
      "       left       1.00      0.93      0.96      2385\n",
      "\n",
      "avg / total       0.97      0.96      0.96      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.91      0.99      0.95      1171\n",
      "       left       0.99      0.91      0.95      1186\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.9622905   0.94257703  0.94677871  0.95658263  0.93977591  0.96078431\n",
      "  0.95658263  0.95378151  0.95658263  0.96498599]\n",
      "Accuratezza: 0.95 (+/- 0.02)\n",
      "Accuratezza training:\n",
      "[ 0.96218487  0.96406347  0.96328563  0.96328563  0.96655258  0.96328563\n",
      "  0.96577474  0.96359676  0.96064095  0.96639701]\n",
      "Accuratezza: 0.96 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.94413408  0.92156863  0.91876751  0.93557423  0.92156863  0.93557423\n",
      "  0.94397759  0.91876751  0.94397759  0.94677871]\n",
      "Recall: 0.93 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.93526299  0.94243933  0.9446173   0.93932794  0.95332918  0.93372744\n",
      "  0.94181705  0.934972    0.9334163   0.94275047]\n",
      "Recall: 0.94 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.97971014  0.9619883   0.97329377  0.97660819  0.95639535  0.98525074\n",
      "  0.9683908   0.98795181  0.9683908   0.98255814]\n",
      "Precision: 0.97 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.98848684  0.98504065  0.98125404  0.98660131  0.97922659  0.99239418\n",
      "  0.98921569  0.99174917  0.98716683  0.98954931]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.96159317  0.94134478  0.94524496  0.95565093  0.93865906  0.95977011\n",
      "  0.95602837  0.9521045   0.95602837  0.96433666]\n",
      "F1: 0.95 (+/- 0.02)\n",
      "f1 training:\n",
      "[ 0.96113865  0.9632692   0.96258719  0.96238444  0.96610437  0.96216736\n",
      "  0.96493465  0.96252402  0.95953942  0.96558317]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "10\n",
      "DATASET BILANCIATO--->\n",
      "[  4.50614353e-01   7.02226251e-02   2.06090482e-02   0.00000000e+00\n",
      "   5.29594961e-02   4.03084516e-01   0.00000000e+00   0.00000000e+00\n",
      "   2.46758988e-03   4.23720628e-05]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.964890282132\n",
      "Accuratezza sul test:\n",
      "0.955876113704\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.94      1.00      0.97      2400\n",
      "       left       1.00      0.93      0.96      2385\n",
      "\n",
      "avg / total       0.97      0.96      0.96      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.92      0.99      0.96      1171\n",
      "       left       0.99      0.92      0.95      1186\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza test:\n",
      "[ 0.96089385  0.95098039  0.94957983  0.95938375  0.95098039  0.96638655\n",
      "  0.96358543  0.94817927  0.95658263  0.95518207]\n",
      "Accuratezza: 0.96 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.96560847  0.96437461  0.96235221  0.96484132  0.96639701  0.96453018\n",
      "  0.96437461  0.96655258  0.96250778  0.96297449]\n",
      "Accuratezza: 0.96 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.96089385  0.91596639  0.91316527  0.92997199  0.92156863  0.94677871\n",
      "  0.94397759  0.92997199  0.93557423  0.93277311]\n",
      "Recall: 0.93 (+/- 0.03)\n",
      "Recall training:\n",
      "[ 0.94833489  0.93466086  0.94337274  0.94306161  0.94772869  0.93963908\n",
      "  0.93839452  0.94399502  0.93466086  0.93652769]\n",
      "Recall: 0.94 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.96089385  0.98493976  0.98489426  0.98809524  0.97916667  0.98542274\n",
      "  0.98250729  0.96511628  0.97660819  0.97653959]\n",
      "Precision: 0.98 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.9822695   0.99371485  0.98059508  0.98601171  0.9844861   0.98886706\n",
      "  0.98982606  0.98859563  0.98978583  0.98883049]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.96089385  0.94920174  0.94767442  0.95815296  0.94949495  0.96571429\n",
      "  0.96285714  0.94721826  0.95565093  0.95415473]\n",
      "F1: 0.96 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.96500396  0.96328363  0.96162385  0.96405852  0.96575777  0.96362476\n",
      "  0.96342437  0.96578068  0.96143383  0.96196868]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "11\n",
      "DATASET BILANCIATO--->\n",
      "[  4.33260455e-01   5.88765319e-02   3.48536263e-02   2.45008869e-03\n",
      "   1.12786693e-01   3.57749925e-01   0.00000000e+00   0.00000000e+00\n",
      "   2.26805298e-05   0.00000000e+00]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.966771159875\n",
      "Accuratezza sul test:\n",
      "0.952906236742\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.94      0.99      0.97      2400\n",
      "       left       0.99      0.94      0.97      2385\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.92      0.99      0.95      1171\n",
      "       left       0.99      0.91      0.95      1186\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.96648045  0.96358543  0.95098039  0.95798319  0.94257703  0.96638655\n",
      "  0.95098039  0.95938375  0.95658263  0.96218487]\n",
      "Accuratezza: 0.96 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.96311858  0.96701929  0.96686372  0.96499689  0.96499689  0.96437461\n",
      "  0.96406347  0.96639701  0.96375233  0.96437461]\n",
      "Accuratezza: 0.96 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.94692737  0.93837535  0.92436975  0.92997199  0.91876751  0.94397759\n",
      "  0.93557423  0.92997199  0.95238095  0.92997199]\n",
      "Recall: 0.94 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.93308434  0.9446173   0.94306161  0.94212819  0.94803983  0.94150591\n",
      "  0.94026136  0.93808339  0.9390168   0.93683883]\n",
      "Recall: 0.94 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.98546512  0.98820059  0.97633136  0.9851632   0.96470588  0.98826979\n",
      "  0.96531792  0.98809524  0.96045198  0.99401198]\n",
      "Precision: 0.98 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.99271523  0.98892508  0.99019928  0.98728399  0.98132045  0.98663189\n",
      "  0.98725907  0.99439314  0.98788871  0.99143892]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.96581197  0.96264368  0.94964029  0.95677233  0.94117647  0.96561605\n",
      "  0.95021337  0.95815296  0.95639944  0.96092619]\n",
      "F1: 0.96 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.96197658  0.96626353  0.96605578  0.96417768  0.9643931   0.96354084\n",
      "  0.96318725  0.96541787  0.96283299  0.96336586]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "12\n",
      "DATASET BILANCIATO--->\n",
      "[  4.70848557e-01   9.50481091e-02   2.06313799e-02   1.50277393e-04\n",
      "   5.79729468e-02   3.51690038e-01   1.84106968e-04   0.00000000e+00\n",
      "   0.00000000e+00   3.47458456e-03]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.967607105538\n",
      "Accuratezza sul test:\n",
      "0.953754773017\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.95      0.99      0.97      2400\n",
      "       left       0.99      0.95      0.97      2385\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4785\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.93      0.98      0.95      1171\n",
      "       left       0.98      0.93      0.95      1186\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2357\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.97067039  0.95238095  0.94957983  0.96498599  0.94677871  0.95658263\n",
      "  0.96358543  0.95378151  0.95798319  0.95938375]\n",
      "Accuratezza: 0.96 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.96607532  0.96873055  0.96608587  0.96826385  0.96577474  0.96624144\n",
      "  0.9639079   0.96764157  0.96468575  0.96453018]\n",
      "Accuratezza: 0.97 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.95810056  0.92997199  0.91876751  0.93557423  0.91876751  0.94397759\n",
      "  0.95798319  0.93557423  0.94117647  0.94117647]\n",
      "Recall: 0.94 (+/- 0.03)\n",
      "Recall training:\n",
      "[ 0.94460006  0.95084007  0.94523958  0.9502178   0.94959552  0.94555072\n",
      "  0.94803983  0.94990666  0.94150591  0.94368388]\n",
      "Recall: 0.95 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.98280802  0.97360704  0.97910448  0.99404762  0.97329377  0.9683908\n",
      "  0.96883853  0.97093023  0.97391304  0.97674419]\n",
      "Precision: 0.98 (+/- 0.01)\n",
      "Precision training:\n",
      "[ 0.98699187  0.98612456  0.98636364  0.98579729  0.98135048  0.98636806\n",
      "  0.97911311  0.98483871  0.98727569  0.98474026]\n",
      "Precision: 0.98 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.97029703  0.9512894   0.94797688  0.96392496  0.94524496  0.95602837\n",
      "  0.96338028  0.95292439  0.95726496  0.95863053]\n",
      "F1: 0.96 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.96533079  0.96816094  0.96536384  0.96768061  0.96521189  0.9655282\n",
      "  0.96332596  0.96705733  0.96384775  0.96377502]\n",
      "F1: 0.97 (+/- 0.00)\n",
      "[579, 398, 295, 285, 207, 190, 174, 174, 168, 159, 155]\n",
      "[308, 204, 176, 173, 125, 117, 113, 119, 104, 111, 109]\n"
     ]
    }
   ],
   "source": [
    "#Accuratezza di training e test DEL DATASET SBILANCIATO all'aumentare di max_deph da 2 a 12 per parametri trovati nella prima prova \n",
    "#(PER VEDERE SE E QUANDO SI ENTRA IN OVERFITTING)\n",
    "max_d=[2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "errors_training=[]\n",
    "errors_test=[]\n",
    "for d in max_d:\n",
    "    clf = tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=d,\n",
    "            max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=32, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=1713394782, splitter='best')\n",
    "    clf= clf.fit(train_sel_res_x, train_sel_res_y)\n",
    "    if(d==9):\n",
    "        clf_def=clf\n",
    "\n",
    "    print (\"Max_depth:\")\n",
    "    print(d)\n",
    "    print (\"DATASET BILANCIATO--->\")\n",
    "    print (clf.feature_importances_)\n",
    "\n",
    "    print(\"TRANING E TEST FORMATI CON HOLDOUT->\")\n",
    "    train_sel_res_pred = clf.predict(train_sel_res_x)\n",
    "    cm=confusion_matrix(train_sel_res_y, train_sel_res_pred)\n",
    "    errors_training.append(cm[0][1]+cm[1][0])\n",
    "    test_sel_res_pred = clf.predict(test_sel_res_x)\n",
    "    cm_t=confusion_matrix(test_sel_res_y, test_sel_res_pred)\n",
    "    errors_test.append(cm_t[0][1]+cm_t[1][0])\n",
    "    # Accuratezza sul training e sul test\n",
    "    print (\"Accuratezza sul training:\")\n",
    "    print (metrics.accuracy_score(train_sel_res_y, train_sel_res_pred))\n",
    "    print (\"Accuratezza sul test:\")\n",
    "    print (metrics.accuracy_score(test_sel_res_y, test_sel_res_pred))\n",
    "    # recall, precision, f1_measure su training e su test\n",
    "    print (\"r, p, f1-score sul training:\")\n",
    "    print(classification_report(train_sel_res_y, \n",
    "                            train_sel_res_pred, \n",
    "                            target_names=['Not left', 'left']))\n",
    "    print (\"r, p, f1-score sul test:\")\n",
    "    print(classification_report(test_sel_res_y, \n",
    "                            test_sel_res_pred, \n",
    "                            target_names=['Not left', 'left']))\n",
    "\n",
    "    print(\"TRANING E TEST FORMATI CON CROSS-VALIDATION->\")\n",
    "\n",
    "    scores = cross_validate(clf, \n",
    "                        train_sel_features_res, train_sel_target_res, scoring=['accuracy','recall','precision','f1'],\n",
    "                        cv=10, return_train_score=True)\n",
    "\n",
    "    print (\"Accuratezza test:\")\n",
    "    print(scores['test_accuracy'])\n",
    "    print ('Accuratezza: %0.2f (+/- %0.2f)' % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2))\n",
    "    print (\"Accuratezza training:\")\n",
    "    print(scores['train_accuracy'])\n",
    "    print ('Accuratezza: %0.2f (+/- %0.2f)' % (scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
    "    print (\"Recall test:\")\n",
    "    print(scores['test_recall'])\n",
    "    print ('Recall: %0.2f (+/- %0.2f)' % (scores['test_recall'].mean(), scores['test_recall'].std() * 2))\n",
    "    print (\"Recall training:\")\n",
    "    print(scores['train_recall'])\n",
    "    print ('Recall: %0.2f (+/- %0.2f)' % (scores['train_recall'].mean(), scores['train_recall'].std() * 2))\n",
    "    print (\"Precision test:\")\n",
    "    print(scores['test_precision'])\n",
    "    print ('Precision: %0.2f (+/- %0.2f)' % (scores['test_precision'].mean(), scores['test_precision'].std() * 2))\n",
    "    print (\"Precision training:\")\n",
    "    print(scores['train_precision'])\n",
    "    print ('Precision: %0.2f (+/- %0.2f)' % (scores['train_precision'].mean(), scores['train_precision'].std() * 2))\n",
    "    print (\"f1 test:\")\n",
    "    print(scores['test_f1'])\n",
    "    print ('F1: %0.2f (+/- %0.2f)' % (scores['test_f1'].mean(), scores['test_f1'].std() * 2))\n",
    "    print (\"f1 training:\")\n",
    "    print(scores['train_f1'])\n",
    "    print ('F1: %0.2f (+/- %0.2f)' % (scores['train_f1'].mean(), scores['train_f1'].std() * 2))\n",
    "    \n",
    "print(errors_training)\n",
    "print(errors_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x8aa3ef0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAJQCAYAAABFO0g9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8a75048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#GRAFICO PER VEDERE OVERFITTING\n",
    "plt.subplots(1, 1, figsize=(12,10))\n",
    "\n",
    "test, = plt.plot(max_d, errors_test, label=\"Test set\")\n",
    "training, = plt.plot(max_d, errors_training, label=\"Training set\")\n",
    "scatter_plot= plt.legend(handles=[test, training])\n",
    "plt.xlabel(\"number of nodes\")\n",
    "plt.ylabel(\"Errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

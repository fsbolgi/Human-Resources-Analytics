{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from numpy.random import randint \n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>salary</th>\n",
       "      <th>average_daily_hours</th>\n",
       "      <th>time_spent_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>departments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>7.302326</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>12.186047</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>12.651163</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>10.372093</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>7.395349</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  left  \\\n",
       "0                0.38             0.53               2     1   \n",
       "1                0.80             0.86               5     1   \n",
       "2                0.11             0.88               7     1   \n",
       "3                0.72             0.87               5     1   \n",
       "4                0.37             0.52               2     1   \n",
       "\n",
       "   promotion_last_5years  salary  average_daily_hours  time_spent_company  \\\n",
       "0                      0     low             7.302326                   3   \n",
       "1                      0  medium            12.186047                   6   \n",
       "2                      0  medium            12.651163                   4   \n",
       "3                      0     low            10.372093                   5   \n",
       "4                      0     low             7.395349                   3   \n",
       "\n",
       "   work_accident departments  \n",
       "0              0       sales  \n",
       "1              0       sales  \n",
       "2              0       sales  \n",
       "3              0       sales  \n",
       "4              0       sales  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creazione di average_daily_hours, time_spenT_company, work_accident e departments\n",
    "df = pd.read_csv(\"HR_comma_sep.csv\")\n",
    "df['average_daily_hours']=df['average_montly_hours']/21.5\n",
    "df=df.drop(['average_montly_hours'], axis=1)\n",
    "\n",
    "df ['time_spent_company'] = df['time_spend_company']\n",
    "df=df.drop(['time_spend_company'], axis=1)\n",
    "\n",
    "df ['work_accident'] = df['Work_accident']\n",
    "df=df.drop(['Work_accident'], axis=1)\n",
    "\n",
    "df ['departments'] = df['sales']\n",
    "df=df.drop(['sales'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funzione per trasformare le variabile categoriche in numeriche dumpy/binarie (sklearn.DecisionTree funziona solo con numeri e fa solo due split per nodo)\n",
    "def clean_data(df):\n",
    "    # Get the unique values of departments\n",
    "    departments_locs = sorted(df['departments'].unique())\n",
    "\n",
    "    # Generate a mapping of departments from a string to a number representation        \n",
    "    departments_locs_mapping = dict(zip(departments_locs, \n",
    "                                     range(0, len(departments_locs) + 1)))\n",
    "    \n",
    "    # Transform departments from a string to a number representation\n",
    "    df['departments_val'] = df['departments'].map(departments_locs_mapping).astype(int)\n",
    "    \n",
    "    # Transform departments from a string to dummy variables\n",
    "    df = pd.concat([df, pd.get_dummies(df['departments'], prefix='departments_val')], axis=1)\n",
    "    \n",
    "    # drop departments and departments_val\n",
    "    df=df.drop(['departments'], axis=1)\n",
    "    df=df.drop(['departments_val'], axis=1)\n",
    "    \n",
    "    \n",
    "     # Get the unique values of salary\n",
    "    salary_locs = sorted(df['salary'].unique())\n",
    "\n",
    "    # Generate a mapping of salary from a string to a number representation        \n",
    "    salary_locs_mapping = dict(zip(salary_locs, [2, 0, 1]))\n",
    "    \n",
    "    # Transform salary from a string to a number representation\n",
    "    df['salary_val'] = df['salary'].map(salary_locs_mapping).astype(int)\n",
    "    \n",
    "    # Transform salary from a string to dummy variables\n",
    "    df = pd.concat([df, pd.get_dummies(df['salary'], prefix='salary_val')], axis=1)\n",
    "    \n",
    "    # drop salary and salary_val\n",
    "    df=df.drop(['salary'], axis=1)\n",
    "    df=df.drop(['salary_val'], axis=1)\n",
    "    return df\n",
    "df= clean_data (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>average_daily_hours</th>\n",
       "      <th>time_spent_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>salary_val_high</th>\n",
       "      <th>salary_val_low</th>\n",
       "      <th>salary_val_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.302326</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.186047</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.651163</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.372093</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.395349</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  left  \\\n",
       "0                0.38             0.53               2     1   \n",
       "1                0.80             0.86               5     1   \n",
       "2                0.11             0.88               7     1   \n",
       "3                0.72             0.87               5     1   \n",
       "4                0.37             0.52               2     1   \n",
       "\n",
       "   promotion_last_5years  average_daily_hours  time_spent_company  \\\n",
       "0                      0             7.302326                   3   \n",
       "1                      0            12.186047                   6   \n",
       "2                      0            12.651163                   4   \n",
       "3                      0            10.372093                   5   \n",
       "4                      0             7.395349                   3   \n",
       "\n",
       "   work_accident  salary_val_high  salary_val_low  salary_val_medium  \n",
       "0              0                0               1                  0  \n",
       "1              0                0               0                  1  \n",
       "2              0                0               0                  1  \n",
       "3              0                0               1                  0  \n",
       "4              0                0               1                  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creazione di un nuovo dataset da cui vengono eliminate alcune variabili che potrebbero non avere importanza nella classificazione\n",
    "df_selected_feat=df.drop(['departments_val_IT', 'departments_val_RandD', 'departments_val_accounting','departments_val_hr', 'departments_val_management',      \n",
    "'departments_val_marketing',        \n",
    "'departments_val_product_mng',     \n",
    "'departments_val_sales',          \n",
    "'departments_val_support',          \n",
    "'departments_val_technical'],axis=1)\n",
    "df_selected_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#divisione di df_selected_feat in training e test\n",
    "\n",
    "# conversione del DataFrame in un numpy array:\n",
    "train_data_sel = df_selected_feat.values\n",
    "\n",
    "#DATASET NON BILANCIATO: CI SONO 3571 LEFT E 11428 NON LEFT\n",
    "# selezione delle features senza la colonna left (target)\n",
    "train_sel_features = np.delete(train_data_sel,np.s_[3:4], axis=1)\n",
    "\n",
    "# selezione del target left\n",
    "train_sel_target = np.delete(train_data_sel,np.s_[0:3], axis=1)\n",
    "train_sel_target = train_sel_target[:, 0]\n",
    "\n",
    "# divisione del DATASET SBILANCIATO in training e in test - tecnica holdout->1/3 per test set(train_x e test_x formano insieme tutto il dataset mentre train_y e test_y corrispondono al target)\n",
    "train_sel_x, test_sel_x, train_sel_y, test_sel_y = train_test_split(train_sel_features, \n",
    "                                                    train_sel_target, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=30)\n",
    "param_grid = {\"criterion\":[\"gini\",\"entropy\"],\n",
    "              \"max_features\":range(1,11),\n",
    "              \"max_depth\": [2,3,4,5,6,7,8,9,10,11,12,None],\n",
    "              \"min_samples_split\": range(10, 431),\n",
    "              \"bootstrap\": [True]\n",
    "             }\n",
    "              \n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(clf, param_distributions=param_grid, scoring=make_scorer(accuracy_score), n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'criterion': ['gini', 'entropy'], 'max_features': range(1, 11), 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, None], 'min_samples_split': range(10, 431), 'bootstrap': [True]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=make_scorer(accuracy_score),\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(train_sel_features, train_sel_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.978 (std: 0.003)\n",
      "Parameters: {'min_samples_split': 38, 'max_features': 6, 'max_depth': 9, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.978 (std: 0.003)\n",
      "Parameters: {'min_samples_split': 30, 'max_features': 8, 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.978 (std: 0.003)\n",
      "Parameters: {'min_samples_split': 317, 'max_features': 8, 'max_depth': 10, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(search.cv_results_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
       "            max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1666303073, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET SBILANCIATO--->\n",
      "[  5.30260008e-01   1.12363238e-01   9.66121750e-02   1.45148947e-04\n",
      "   9.14130942e-02   1.67516690e-01   0.00000000e+00   1.67259267e-03\n",
      "   1.70537878e-05   0.00000000e+00]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.979798984974\n",
      "Accuratezza sul test:\n",
      "0.977171717172\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      1.00      0.99      7610\n",
      "       left       0.99      0.93      0.96      2439\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      0.99      0.99      3818\n",
      "       left       0.98      0.92      0.95      1132\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.98201199  0.976       0.978       0.97533333  0.97733333  0.98066667\n",
      "  0.97933333  0.974       0.98065377  0.97998666]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Accuratezza training:\n",
      "[ 0.97925619  0.98022076  0.98051708  0.98140603  0.9800726   0.97844285\n",
      "  0.9797022   0.97992444  0.97962963  0.97903704]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93854749  0.9047619   0.91596639  0.92717087  0.91596639  0.92997199\n",
      "  0.92997199  0.91316527  0.93277311  0.92436975]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92281357  0.92657125  0.92968264  0.93186061  0.92906036  0.92252645\n",
      "  0.92501556  0.92439328  0.9253267   0.92221531]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.98533724  0.99384615  0.99090909  0.96783626  0.98791541  0.98809524\n",
      "  0.98224852  0.9760479   0.9852071   0.99099099]\n",
      "Precision: 0.98 (+/- 0.01)\n",
      "Precision training:\n",
      "[ 0.98932266  0.98969757  0.9877686   0.98942848  0.98645524  0.98603259\n",
      "  0.98902196  0.99066355  0.98836823  0.98898899]\n",
      "Precision: 0.99 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.96137339  0.94721408  0.95196507  0.94706724  0.9505814   0.95815296\n",
      "  0.95539568  0.94356006  0.95827338  0.95652174]\n",
      "F1: 0.95 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.95491143  0.95709465  0.95784581  0.95978209  0.95689793  0.95322295\n",
      "  0.95594855  0.95638178  0.9558091   0.95443568]\n",
      "F1: 0.96 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#prova dell'albero ottenuto \n",
    "clf = tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
    "            max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=1666303073, splitter='best')\n",
    "clf = clf.fit(train_sel_x, train_sel_y)\n",
    "print (\"DATASET SBILANCIATO--->\")\n",
    "print (clf.feature_importances_)\n",
    "\n",
    "print(\"TRANING E TEST FORMATI CON HOLDOUT->\")\n",
    "train_sel_pred = clf.predict(train_sel_x)\n",
    "test_sel_pred = clf.predict(test_sel_x)\n",
    "# Accuratezza sul training e sul test\n",
    "print (\"Accuratezza sul training:\")\n",
    "print (metrics.accuracy_score(train_sel_y, train_sel_pred))\n",
    "print (\"Accuratezza sul test:\")\n",
    "print (metrics.accuracy_score(test_sel_y, test_sel_pred))\n",
    "# recall, precision, f1_measure su training e su test\n",
    "print (\"r, p, f1-score sul training:\")\n",
    "print(classification_report(train_sel_y, \n",
    "                            train_sel_pred, \n",
    "                            target_names=['Not left', 'left']))\n",
    "print (\"r, p, f1-score sul test:\")\n",
    "print(classification_report(test_sel_y, \n",
    "                            test_sel_pred, \n",
    "                            target_names=['Not left', 'left']))\n",
    "\n",
    "print(\"TRANING E TEST FORMATI CON CROSS-VALIDATION->\")\n",
    "\n",
    "scores = cross_validate(clf, \n",
    "                        train_sel_features, train_sel_target, scoring=['accuracy','recall','precision','f1'],\n",
    "                        cv=10, return_train_score=True)\n",
    "\n",
    "print (\"Accuratezza test:\")\n",
    "print(scores['test_accuracy'])\n",
    "print ('Accuratezza: %0.2f (+/- %0.2f)' % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2))\n",
    "print (\"Accuratezza training:\")\n",
    "print(scores['train_accuracy'])\n",
    "print ('Accuratezza: %0.2f (+/- %0.2f)' % (scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
    "print (\"Recall test:\")\n",
    "print(scores['test_recall'])\n",
    "print ('Recall: %0.2f (+/- %0.2f)' % (scores['test_recall'].mean(), scores['test_recall'].std() * 2))\n",
    "print (\"Recall training:\")\n",
    "print(scores['train_recall'])\n",
    "print ('Recall: %0.2f (+/- %0.2f)' % (scores['train_recall'].mean(), scores['train_recall'].std() * 2))\n",
    "print (\"Precision test:\")\n",
    "print(scores['test_precision'])\n",
    "print ('Precision: %0.2f (+/- %0.2f)' % (scores['test_precision'].mean(), scores['test_precision'].std() * 2))\n",
    "print (\"Precision training:\")\n",
    "print(scores['train_precision'])\n",
    "print ('Precision: %0.2f (+/- %0.2f)' % (scores['train_precision'].mean(), scores['train_precision'].std() * 2))\n",
    "print (\"f1 test:\")\n",
    "print(scores['test_f1'])\n",
    "print ('F1: %0.2f (+/- %0.2f)' % (scores['test_f1'].mean(), scores['test_f1'].std() * 2))\n",
    "print (\"f1 training:\")\n",
    "print(scores['train_f1'])\n",
    "print ('F1: %0.2f (+/- %0.2f)' % (scores['train_f1'].mean(), scores['train_f1'].std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth:\n",
      "2\n",
      "DATASET SBILANCIATO--->\n",
      "[ 0.74983436  0.          0.25016564  0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.845755796597\n",
      "Accuratezza sul test:\n",
      "0.858383838384\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.84      0.98      0.91      7610\n",
      "       left       0.88      0.42      0.57      2439\n",
      "\n",
      "avg / total       0.85      0.85      0.82     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.86      0.98      0.91      3818\n",
      "       left       0.88      0.44      0.59      1132\n",
      "\n",
      "avg / total       0.86      0.86      0.84      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.85609594  0.84866667  0.83733333  0.844       0.85066667  0.85466667\n",
      "  0.84333333  0.854       0.85256838  0.85790527]\n",
      "Accuratezza: 0.85 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.84923692  0.85006297  0.85132232  0.85058152  0.84984073  0.84939625\n",
      "  0.8506556   0.84947033  0.84962963  0.84903704]\n",
      "Accuratezza: 0.85 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.44972067  0.40056022  0.40336134  0.40336134  0.43697479  0.46778711\n",
      "  0.41736695  0.43977591  0.42577031  0.44257703]\n",
      "Recall: 0.43 (+/- 0.04)\n",
      "Recall training:\n",
      "[ 0.42639278  0.43186061  0.43154947  0.43154947  0.42781581  0.42439328\n",
      "  0.42999378  0.42750467  0.42906036  0.42719353]\n",
      "Recall: 0.43 (+/- 0.00)\n",
      "Precision test:\n",
      "[ 0.89444444  0.91666667  0.82285714  0.87272727  0.87150838  0.85641026\n",
      "  0.84659091  0.89204545  0.9047619   0.91860465]\n",
      "Precision: 0.88 (+/- 0.06)\n",
      "Precision training:\n",
      "[ 0.87708067  0.87515763  0.88513082  0.87951807  0.87971849  0.88170653\n",
      "  0.88250319  0.87739464  0.87611182  0.87452229]\n",
      "Precision: 0.88 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.59851301  0.55750487  0.54135338  0.55172414  0.58208955  0.60507246\n",
      "  0.55909944  0.5891182   0.57904762  0.5973535 ]\n",
      "F1: 0.58 (+/- 0.04)\n",
      "f1 training:\n",
      "[ 0.57382199  0.57833333  0.58021334  0.5790023   0.57567511  0.57298887\n",
      "  0.57824268  0.5748954   0.57602339  0.57399666]\n",
      "F1: 0.58 (+/- 0.00)\n",
      "Max_depth:\n",
      "3\n",
      "DATASET SBILANCIATO--->\n",
      "[ 0.42982721  0.06093679  0.11175694  0.          0.16216506  0.2330764   0.\n",
      "  0.00223761  0.          0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.927754005374\n",
      "Accuratezza sul test:\n",
      "0.925858585859\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      0.93      0.95      7610\n",
      "       left       0.80      0.93      0.86      2439\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      0.93      0.95      3818\n",
      "       left       0.79      0.93      0.85      1132\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.9407062   0.94066667  0.92866667  0.934       0.92733333  0.93266667\n",
      "  0.942       0.92933333  0.90460307  0.89059373]\n",
      "Accuratezza: 0.93 (+/- 0.03)\n",
      "Accuratezza training:\n",
      "[ 0.92554453  0.92555004  0.92688347  0.92629084  0.92703163  0.926439\n",
      "  0.92540188  0.92680939  0.92955556  0.93111111]\n",
      "Accuratezza: 0.93 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93854749  0.9047619   0.91596639  0.93837535  0.91876751  0.92156863\n",
      "  0.93557423  0.91036415  0.93277311  0.92717087]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92281357  0.92657125  0.9253267   0.92283759  0.92501556  0.92470442\n",
      "  0.92314872  0.92594897  0.92345986  0.92408214]\n",
      "Recall: 0.92 (+/- 0.00)\n",
      "Precision test:\n",
      "[ 0.8337469   0.85449735  0.80940594  0.8131068   0.80392157  0.81840796\n",
      "  0.83919598  0.81453634  0.73672566  0.70575693]\n",
      "Precision: 0.80 (+/- 0.09)\n",
      "Precision training:\n",
      "[ 0.79661472  0.79476915  0.79924751  0.79881497  0.79983858  0.79828096\n",
      "  0.79608264  0.79871176  0.80805881  0.81236324]\n",
      "Precision: 0.80 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.88304862  0.87891156  0.85939553  0.87126138  0.85751634  0.86693017\n",
      "  0.88476821  0.85978836  0.82323857  0.80145278]\n",
      "F1: 0.86 (+/- 0.05)\n",
      "f1 training:\n",
      "[ 0.85508291  0.85562419  0.85767844  0.85635917  0.85788487  0.85685455\n",
      "  0.85492004  0.85763689  0.86191375  0.86462882]\n",
      "F1: 0.86 (+/- 0.01)\n",
      "Max_depth:\n",
      "4\n",
      "DATASET SBILANCIATO--->\n",
      "[ 0.57418966  0.07030394  0.09449179  0.          0.09306974  0.16608946\n",
      "  0.          0.00185541  0.          0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.963777490298\n",
      "Accuratezza sul test:\n",
      "0.960202020202\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.97      0.98      0.98      7610\n",
      "       left       0.93      0.92      0.93      2439\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.97      0.97      0.97      3818\n",
      "       left       0.91      0.91      0.91      1132\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.97001999  0.96733333  0.96066667  0.96533333  0.95933333  0.96266667\n",
      "  0.968       0.96133333  0.95063376  0.94863242]\n",
      "Accuratezza: 0.96 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.96162394  0.96170087  0.96170087  0.96110823  0.96184903  0.96251574\n",
      "  0.96162679  0.9622935   0.96274074  0.96296296]\n",
      "Accuratezza: 0.96 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.9301676   0.89915966  0.91596639  0.92997199  0.91596639  0.91876751\n",
      "  0.92436975  0.91036415  0.92156863  0.91596639]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.91970121  0.92314872  0.91661481  0.91941506  0.91661481  0.92097075\n",
      "  0.92034848  0.92190417  0.91879278  0.91754823]\n",
      "Recall: 0.92 (+/- 0.00)\n",
      "Precision test:\n",
      "[ 0.94334278  0.96107784  0.91853933  0.92479109  0.91340782  0.92394366\n",
      "  0.94017094  0.92592593  0.87733333  0.87433155]\n",
      "Precision: 0.92 (+/- 0.05)\n",
      "Precision training:\n",
      "[ 0.91912908  0.91658943  0.92206573  0.91741695  0.92264328  0.92154421\n",
      "  0.91863354  0.91990065  0.92425665  0.92619347]\n",
      "Precision: 0.92 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.93670886  0.92908828  0.91725105  0.9273743   0.91468531  0.92134831\n",
      "  0.93220339  0.9180791   0.8989071   0.89466484]\n",
      "F1: 0.92 (+/- 0.03)\n",
      "f1 training:\n",
      "[ 0.91941506  0.91985739  0.91933219  0.91841492  0.91961917  0.92125739\n",
      "  0.91949021  0.92090132  0.92151662  0.92185058]\n",
      "F1: 0.92 (+/- 0.00)\n",
      "Max_depth:\n",
      "5\n",
      "DATASET SBILANCIATO--->\n",
      "[ 0.4511356   0.10642148  0.20818153  0.00421054  0.06425516  0.16396364\n",
      "  0.          0.00183206  0.          0.        ]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.965767738083\n",
      "Accuratezza sul test:\n",
      "0.963838383838\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      0.98      0.98      7610\n",
      "       left       0.94      0.92      0.93      2439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      0.98      0.98      3818\n",
      "       left       0.92      0.92      0.92      1132\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.97401732  0.96733333  0.95933333  0.974       0.96        0.96533333\n",
      "  0.97066667  0.962       0.95997332  0.9593062 ]\n",
      "Accuratezza: 0.97 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.96443918  0.96518261  0.96718275  0.96962738  0.96710867  0.96829395\n",
      "  0.96466405  0.96547892  0.96718519  0.96688889]\n",
      "Accuratezza: 0.97 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.94134078  0.89915966  0.89915966  0.93277311  0.91036415  0.92156863\n",
      "  0.92997199  0.91316527  0.92436975  0.91876751]\n",
      "Recall: 0.92 (+/- 0.03)\n",
      "Recall training:\n",
      "[ 0.92405851  0.92874922  0.92065961  0.9197262   0.91941506  0.92314872\n",
      "  0.92408214  0.92719353  0.92003734  0.91785937]\n",
      "Recall: 0.92 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.94929577  0.96107784  0.92774566  0.95689655  0.92067989  0.93201133\n",
      "  0.94586895  0.92613636  0.90909091  0.91111111]\n",
      "Precision: 0.93 (+/- 0.03)\n",
      "Precision training:\n",
      "[ 0.92636505  0.92529448  0.94026057  0.95109395  0.9410828   0.94250318\n",
      "  0.9272557   0.92777086  0.94082087  0.94158953]\n",
      "Precision: 0.94 (+/- 0.02)\n",
      "f1 test:\n",
      "[ 0.94530154  0.92908828  0.91322902  0.94468085  0.91549296  0.92676056\n",
      "  0.93785311  0.91960508  0.91666667  0.91492329]\n",
      "F1: 0.93 (+/- 0.02)\n",
      "f1 training:\n",
      "[ 0.92521035  0.92701863  0.93035686  0.93514711  0.93012276  0.93272556\n",
      "  0.9256662   0.9274821   0.93031304  0.92957303]\n",
      "F1: 0.93 (+/- 0.01)\n",
      "Max_depth:\n",
      "6\n",
      "DATASET SBILANCIATO--->\n",
      "[  4.59779885e-01   5.32365688e-02   8.92560231e-02   1.51444176e-04\n",
      "   1.90314842e-01   2.05405392e-01   1.10709947e-04   1.74513438e-03\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.974126778784\n",
      "Accuratezza sul test:\n",
      "0.971717171717\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      0.99      0.98      7610\n",
      "       left       0.97      0.92      0.95      2439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.97      0.99      0.98      3818\n",
      "       left       0.96      0.91      0.94      1132\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza test:\n",
      "[ 0.97601599  0.97133333  0.966       0.97533333  0.96466667  0.97133333\n",
      "  0.97533333  0.96533333  0.97264843  0.97131421]\n",
      "Accuratezza: 0.97 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.97236628  0.97222016  0.97110897  0.97510927  0.97133121  0.97496111\n",
      "  0.97199793  0.97296096  0.97044444  0.97096296]\n",
      "Accuratezza: 0.97 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.9273743   0.89355742  0.90196078  0.92436975  0.90756303  0.92436975\n",
      "  0.91876751  0.90196078  0.92717087  0.91876751]\n",
      "Recall: 0.91 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.91192032  0.91381456  0.91599253  0.91754823  0.91785937  0.92594897\n",
      "  0.91194773  0.91319228  0.9141257   0.91474798]\n",
      "Recall: 0.92 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.97076023  0.9845679   0.95266272  0.97058824  0.94186047  0.95375723\n",
      "  0.97619048  0.94985251  0.9566474   0.95906433]\n",
      "Precision: 0.96 (+/- 0.03)\n",
      "Precision training:\n",
      "[ 0.97019868  0.96771005  0.96083551  0.97649007  0.95997397  0.96749025\n",
      "  0.96860542  0.97153261  0.95981705  0.96141269]\n",
      "Precision: 0.97 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.94857143  0.93685756  0.92661871  0.94691535  0.92439372  0.93883357\n",
      "  0.94660895  0.92528736  0.94167852  0.93848355]\n",
      "F1: 0.94 (+/- 0.02)\n",
      "f1 training:\n",
      "[ 0.94015723  0.9399904   0.93787831  0.94610202  0.93844441  0.94626391\n",
      "  0.93942308  0.9414595   0.93641434  0.9375    ]\n",
      "F1: 0.94 (+/- 0.01)\n",
      "Max_depth:\n",
      "7\n",
      "DATASET SBILANCIATO--->\n",
      "[  3.52079101e-01   1.18377488e-01   1.59000218e-01   1.49176109e-04\n",
      "   1.91837964e-01   1.76837055e-01   0.00000000e+00   1.71899880e-03\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.976017514181\n",
      "Accuratezza sul test:\n",
      "0.974545454545\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.97      0.99      0.98      7610\n",
      "       left       0.98      0.92      0.95      2439\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.97      0.99      0.98      3818\n",
      "       left       0.97      0.91      0.94      1132\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.9793471   0.97333333  0.97533333  0.97533333  0.97066667  0.97466667\n",
      "  0.98066667  0.97333333  0.97531688  0.97731821]\n",
      "Accuratezza: 0.98 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.97762632  0.9771835   0.97762797  0.97903548  0.97651678  0.97785021\n",
      "  0.97777613  0.97585006  0.97755556  0.97725926]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.94413408  0.91036415  0.91036415  0.92436975  0.9047619   0.92997199\n",
      "  0.93277311  0.91596639  0.93277311  0.92997199]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92468098  0.93154947  0.92252645  0.92563783  0.9181705   0.92719353\n",
      "  0.92688239  0.92501556  0.92719353  0.92563783]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.96848138  0.97597598  0.98484848  0.97058824  0.96996997  0.96231884\n",
      "  0.9852071   0.97032641  0.96242775  0.97360704]\n",
      "Precision: 0.97 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.98020455  0.97144711  0.9824387   0.98542564  0.98202995  0.97865353\n",
      "  0.97864652  0.97220405  0.97736963  0.97765363]\n",
      "Precision: 0.98 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.95615276  0.94202899  0.94614265  0.94691535  0.93623188  0.94586895\n",
      "  0.95827338  0.94236311  0.94736842  0.9512894 ]\n",
      "F1: 0.95 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.95163357  0.95108005  0.95154044  0.9545965   0.94902717  0.95222879\n",
      "  0.95206136  0.94802296  0.95162063  0.95093495]\n",
      "F1: 0.95 (+/- 0.00)\n",
      "Max_depth:\n",
      "8\n",
      "DATASET SBILANCIATO--->\n",
      "[  5.42560338e-01   8.31115302e-02   9.89009885e-02   1.46202681e-04\n",
      "   7.60458773e-02   1.97344082e-01   0.00000000e+00   1.68473514e-03\n",
      "   0.00000000e+00   2.06245692e-04]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.979102398249\n",
      "Accuratezza sul test:\n",
      "0.97797979798\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      1.00      0.99      7610\n",
      "       left       0.99      0.92      0.96      2439\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      1.00      0.99      3818\n",
      "       left       0.99      0.92      0.95      1132\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.98001332  0.97533333  0.976       0.97733333  0.972       0.97666667\n",
      "  0.98133333  0.97266667  0.97998666  0.97931955]\n",
      "Accuratezza: 0.98 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.9791821   0.97999852  0.9797022   0.97955404  0.97844285  0.97762797\n",
      "  0.97903548  0.97910956  0.97977778  0.97881481]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.9301676   0.90756303  0.90756303  0.92717087  0.90756303  0.91876751\n",
      "  0.92717087  0.91316527  0.93277311  0.92156863]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92405851  0.92843808  0.93092719  0.92470442  0.92439328  0.92283759\n",
      "  0.92314872  0.92563783  0.92906036  0.92221531]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.9852071   0.98780488  0.99082569  0.97640118  0.97297297  0.98203593\n",
      "  0.99399399  0.9702381   0.98230088  0.99096386]\n",
      "Precision: 0.98 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.98769128  0.98677249  0.98291721  0.98868929  0.9841007   0.98211921\n",
      "  0.98801199  0.98575215  0.98515341  0.988     ]\n",
      "Precision: 0.99 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.95689655  0.9459854   0.94736842  0.95114943  0.93913043  0.94934877\n",
      "  0.95942029  0.94083694  0.95689655  0.95500726]\n",
      "F1: 0.95 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.95481589  0.9567169   0.95621604  0.95562701  0.95331301  0.95155598\n",
      "  0.95447965  0.95474968  0.95628503  0.9539749 ]\n",
      "F1: 0.95 (+/- 0.00)\n",
      "Max_depth:\n",
      "9\n",
      "DATASET SBILANCIATO--->\n",
      "[  5.30260008e-01   1.12363238e-01   9.66121750e-02   1.45148947e-04\n",
      "   9.14130942e-02   1.67516690e-01   0.00000000e+00   1.67259267e-03\n",
      "   1.70537878e-05   0.00000000e+00]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.979798984974\n",
      "Accuratezza sul test:\n",
      "0.977171717172\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      1.00      0.99      7610\n",
      "       left       0.99      0.93      0.96      2439\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      0.99      0.99      3818\n",
      "       left       0.98      0.92      0.95      1132\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.98201199  0.976       0.978       0.97533333  0.97733333  0.98066667\n",
      "  0.97933333  0.974       0.98065377  0.97998666]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Accuratezza training:\n",
      "[ 0.97925619  0.98022076  0.98051708  0.98140603  0.9800726   0.97844285\n",
      "  0.9797022   0.97992444  0.97962963  0.97903704]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93854749  0.9047619   0.91596639  0.92717087  0.91596639  0.92997199\n",
      "  0.92997199  0.91316527  0.93277311  0.92436975]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92281357  0.92657125  0.92968264  0.93186061  0.92906036  0.92252645\n",
      "  0.92501556  0.92439328  0.9253267   0.92221531]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.98533724  0.99384615  0.99090909  0.96783626  0.98791541  0.98809524\n",
      "  0.98224852  0.9760479   0.9852071   0.99099099]\n",
      "Precision: 0.98 (+/- 0.01)\n",
      "Precision training:\n",
      "[ 0.98932266  0.98969757  0.9877686   0.98942848  0.98645524  0.98603259\n",
      "  0.98902196  0.99066355  0.98836823  0.98898899]\n",
      "Precision: 0.99 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.96137339  0.94721408  0.95196507  0.94706724  0.9505814   0.95815296\n",
      "  0.95539568  0.94356006  0.95827338  0.95652174]\n",
      "F1: 0.95 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.95491143  0.95709465  0.95784581  0.95978209  0.95689793  0.95322295\n",
      "  0.95594855  0.95638178  0.9558091   0.95443568]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "10\n",
      "DATASET SBILANCIATO--->\n",
      "[  4.07588161e-01   6.66268317e-02   1.00487475e-01   2.55768057e-04\n",
      "   1.88227620e-01   2.34674777e-01   7.85793119e-05   1.73382768e-03\n",
      "   0.00000000e+00   3.26960335e-04]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.979998009752\n",
      "Accuratezza sul test:\n",
      "0.978383838384\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      1.00      0.99      7610\n",
      "       left       0.99      0.93      0.96      2439\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      1.00      0.99      3818\n",
      "       left       0.98      0.92      0.95      1132\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza test:\n",
      "[ 0.98401066  0.976       0.97666667  0.976       0.978       0.97933333\n",
      "  0.982       0.976       0.98065377  0.98065377]\n",
      "Accuratezza: 0.98 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.98029338  0.98148011  0.98073931  0.98073931  0.98051708  0.98051708\n",
      "  0.97985036  0.98140603  0.98059259  0.97992593]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93854749  0.91316527  0.91036415  0.92156863  0.91316527  0.92997199\n",
      "  0.92717087  0.91876751  0.92997199  0.92156863]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92405851  0.93217175  0.92843808  0.92719353  0.92563783  0.92750467\n",
      "  0.92190417  0.93154947  0.92781581  0.92159303]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.99408284  0.98489426  0.99085366  0.97626113  0.99390244  0.98224852\n",
      "  0.99698795  0.97910448  0.98809524  0.9969697 ]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "Precision training:\n",
      "[ 0.9926446   0.98943197  0.99004645  0.99135063  0.99199733  0.99003653\n",
      "  0.99296247  0.98975207  0.99003984  0.9936263 ]\n",
      "Precision: 0.99 (+/- 0.00)\n",
      "f1 test:\n",
      "[ 0.96551724  0.94767442  0.94890511  0.9481268   0.95182482  0.95539568\n",
      "  0.96081277  0.94797688  0.95815296  0.95778748]\n",
      "F1: 0.95 (+/- 0.01)\n",
      "f1 training:\n",
      "[ 0.95712444  0.95994873  0.95825305  0.95819936  0.9576694   0.957751\n",
      "  0.95611488  0.95976919  0.95791841  0.95625504]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "11\n",
      "DATASET SBILANCIATO--->\n",
      "[  4.07267009e-01   6.53855764e-02   1.00410225e-01   2.33994679e-04\n",
      "   1.95157152e-01   2.29138622e-01   6.17991275e-05   1.70500778e-03\n",
      "   6.40613955e-04   0.00000000e+00]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.979898497363\n",
      "Accuratezza sul test:\n",
      "0.97797979798\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      1.00      0.99      7610\n",
      "       left       0.99      0.92      0.96      2439\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.98      1.00      0.99      3818\n",
      "       left       0.99      0.91      0.95      1132\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.98334444  0.97533333  0.97466667  0.97466667  0.97533333  0.97333333\n",
      "  0.982       0.97466667  0.98398933  0.97998666]\n",
      "Accuratezza: 0.98 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.97999704  0.98155419  0.98088747  0.98103563  0.9797022   0.980443\n",
      "  0.980443    0.98125787  0.98111111  0.97977778]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93575419  0.91596639  0.90196078  0.92436975  0.91596639  0.92436975\n",
      "  0.92717087  0.91316527  0.93837535  0.92156863]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92374728  0.93092719  0.9334163   0.93154947  0.92999378  0.93217175\n",
      "  0.923771    0.92874922  0.93030492  0.92159303]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.99406528  0.97904192  0.99076923  0.96774194  0.97904192  0.96209913\n",
      "  0.99698795  0.97897898  0.99406528  0.9939577 ]\n",
      "Precision: 0.98 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.99164718  0.99105664  0.98554534  0.98811881  0.98387097  0.98487837\n",
      "  0.99364123  0.99202393  0.9897385   0.99296011]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.96402878  0.94645441  0.94428152  0.94555874  0.94645441  0.94285714\n",
      "  0.96081277  0.94492754  0.96541787  0.95639535]\n",
      "F1: 0.95 (+/- 0.02)\n",
      "f1 training:\n",
      "[ 0.95649372  0.96005134  0.95877277  0.95900064  0.95617402  0.95780051\n",
      "  0.95743309  0.95934437  0.95910184  0.95594643]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "Max_depth:\n",
      "12\n",
      "DATASET SBILANCIATO--->\n",
      "[  3.69162339e-01   8.12760441e-02   2.01354405e-01   2.24086952e-04\n",
      "   1.59685808e-01   1.86208794e-01   1.05254970e-04   1.66567615e-03\n",
      "   3.17590777e-04   0.00000000e+00]\n",
      "TRANING E TEST FORMATI CON HOLDOUT->\n",
      "Accuratezza sul training:\n",
      "0.97890337347\n",
      "Accuratezza sul test:\n",
      "0.977777777778\n",
      "r, p, f1-score sul training:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.97      1.00      0.99      7610\n",
      "       left       0.99      0.92      0.95      2439\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10049\n",
      "\n",
      "r, p, f1-score sul test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not left       0.97      1.00      0.99      3818\n",
      "       left       0.99      0.91      0.95      1132\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4950\n",
      "\n",
      "TRANING E TEST FORMATI CON CROSS-VALIDATION->\n",
      "Accuratezza test:\n",
      "[ 0.98134577  0.97466667  0.97733333  0.97466667  0.97266667  0.976       0.982\n",
      "  0.97666667  0.98198799  0.98198799]\n",
      "Accuratezza: 0.98 (+/- 0.01)\n",
      "Accuratezza training:\n",
      "[ 0.98029338  0.98125787  0.98014668  0.98103563  0.98036892  0.98125787\n",
      "  0.98088747  0.98222091  0.98103704  0.98051852]\n",
      "Accuratezza: 0.98 (+/- 0.00)\n",
      "Recall test:\n",
      "[ 0.93575419  0.9047619   0.91036415  0.92156863  0.90756303  0.91876751\n",
      "  0.93557423  0.92156863  0.93557423  0.92717087]\n",
      "Recall: 0.92 (+/- 0.02)\n",
      "Recall training:\n",
      "[ 0.92530345  0.92781581  0.92314872  0.93372744  0.93123833  0.93154947\n",
      "  0.93279403  0.93403858  0.93123833  0.92626011]\n",
      "Recall: 0.93 (+/- 0.01)\n",
      "Precision test:\n",
      "[ 0.98529412  0.98776758  0.99388379  0.97050147  0.97590361  0.97910448\n",
      "  0.98816568  0.97916667  0.98816568  0.99698795]\n",
      "Precision: 0.98 (+/- 0.02)\n",
      "Precision training:\n",
      "[ 0.99133044  0.99300699  0.99297189  0.98587385  0.98551202  0.98909812\n",
      "  0.98618421  0.99075908  0.98844122  0.99134199]\n",
      "Precision: 0.99 (+/- 0.01)\n",
      "f1 test:\n",
      "[ 0.95988539  0.94444444  0.9502924   0.9454023   0.94049347  0.94797688\n",
      "  0.96115108  0.94949495  0.96115108  0.96081277]\n",
      "F1: 0.95 (+/- 0.02)\n",
      "f1 training:\n",
      "[ 0.95717965  0.95930513  0.95678813  0.95909236  0.95760678  0.95946162\n",
      "  0.9587464   0.9615631   0.9589875   0.95769664]\n",
      "F1: 0.96 (+/- 0.00)\n",
      "[1550, 726, 364, 344, 260, 241, 210, 203, 201, 202, 212]\n",
      "[701, 367, 197, 179, 140, 126, 109, 113, 107, 109, 110]\n"
     ]
    }
   ],
   "source": [
    "#Accuratezza di training e test DEL DATASET SBILANCIATO all'aumentare di max_deph da 2 a 12 per parametri trovati nella prima prova \n",
    "#(PER VEDERE SE E QUANDO SI ENTRA IN OVERFITTING)\n",
    "max_d=[2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "errors_training=[]\n",
    "errors_test=[]\n",
    "for d in max_d:\n",
    "    clf = tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=d,\n",
    "            max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=1666303073, splitter='best')\n",
    "    clf= clf.fit(train_sel_x, train_sel_y)\n",
    "    if(d==9):\n",
    "        clf_def=clf\n",
    "\n",
    "    print (\"Max_depth:\")\n",
    "    print(d)\n",
    "    print (\"DATASET SBILANCIATO--->\")\n",
    "    print (clf.feature_importances_)\n",
    "\n",
    "    print(\"TRANING E TEST FORMATI CON HOLDOUT->\")\n",
    "    train_sel_pred = clf.predict(train_sel_x)\n",
    "    cm=confusion_matrix(train_sel_y, train_sel_pred)\n",
    "    errors_training.append(cm[0][1]+cm[1][0])\n",
    "    test_sel_pred = clf.predict(test_sel_x)\n",
    "    cm_t=confusion_matrix(test_sel_y, test_sel_pred)\n",
    "    errors_test.append(cm_t[0][1]+cm_t[1][0])\n",
    "    # Accuratezza sul training e sul test\n",
    "    print (\"Accuratezza sul training:\")\n",
    "    print (metrics.accuracy_score(train_sel_y, train_sel_pred))\n",
    "    print (\"Accuratezza sul test:\")\n",
    "    print (metrics.accuracy_score(test_sel_y, test_sel_pred))\n",
    "    # recall, precision, f1_measure su training e su test\n",
    "    print (\"r, p, f1-score sul training:\")\n",
    "    print(classification_report(train_sel_y, \n",
    "                            train_sel_pred, \n",
    "                            target_names=['Not left', 'left']))\n",
    "    print (\"r, p, f1-score sul test:\")\n",
    "    print(classification_report(test_sel_y, \n",
    "                            test_sel_pred, \n",
    "                            target_names=['Not left', 'left']))\n",
    "\n",
    "    print(\"TRANING E TEST FORMATI CON CROSS-VALIDATION->\")\n",
    "\n",
    "    scores = cross_validate(clf, \n",
    "                        train_sel_features, train_sel_target, scoring=['accuracy','recall','precision','f1'],\n",
    "                        cv=10, return_train_score=True)\n",
    "\n",
    "    print (\"Accuratezza test:\")\n",
    "    print(scores['test_accuracy'])\n",
    "    print ('Accuratezza: %0.2f (+/- %0.2f)' % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2))\n",
    "    print (\"Accuratezza training:\")\n",
    "    print(scores['train_accuracy'])\n",
    "    print ('Accuratezza: %0.2f (+/- %0.2f)' % (scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
    "    print (\"Recall test:\")\n",
    "    print(scores['test_recall'])\n",
    "    print ('Recall: %0.2f (+/- %0.2f)' % (scores['test_recall'].mean(), scores['test_recall'].std() * 2))\n",
    "    print (\"Recall training:\")\n",
    "    print(scores['train_recall'])\n",
    "    print ('Recall: %0.2f (+/- %0.2f)' % (scores['train_recall'].mean(), scores['train_recall'].std() * 2))\n",
    "    print (\"Precision test:\")\n",
    "    print(scores['test_precision'])\n",
    "    print ('Precision: %0.2f (+/- %0.2f)' % (scores['test_precision'].mean(), scores['test_precision'].std() * 2))\n",
    "    print (\"Precision training:\")\n",
    "    print(scores['train_precision'])\n",
    "    print ('Precision: %0.2f (+/- %0.2f)' % (scores['train_precision'].mean(), scores['train_precision'].std() * 2))\n",
    "    print (\"f1 test:\")\n",
    "    print(scores['test_f1'])\n",
    "    print ('F1: %0.2f (+/- %0.2f)' % (scores['test_f1'].mean(), scores['test_f1'].std() * 2))\n",
    "    print (\"f1 training:\")\n",
    "    print(scores['train_f1'])\n",
    "    print ('F1: %0.2f (+/- %0.2f)' % (scores['train_f1'].mean(), scores['train_f1'].std() * 2))\n",
    "    \n",
    "print(errors_training)\n",
    "print(errors_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xc73dc50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAJQCAYAAABSGdj0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIiJTY/wdyLgGUxjXUOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbe86860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#GRAFICO PER VEDERE OVERFITTING\n",
    "plt.subplots(1, 1, figsize=(12,10))\n",
    "\n",
    "test, = plt.plot(max_d, errors_test, label=\"Test set\")\n",
    "training, = plt.plot(max_d, errors_training, label=\"Training set\")\n",
    "scatter_plot= plt.legend(handles=[test, training])\n",
    "plt.xlabel(\"number of nodes\")\n",
    "plt.ylabel(\"Errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

\section{Classification}
	L’ultima fase di analisi riguarda lo sviluppo di modelli di classificazione costruiti allo scopo di predire se e quali impiegati lasceranno la compagnia, utilizzando l’attributo target \textit{left}. Per fare questo, sono stati usati due principali modelli di classificazione, ovvero Decision Tree e Random Forest. Inoltre, si è deciso di costruire i differenti modelli usando sia il dataset originario, sbilanciato rispetto all’attributo \textit{left} (ci sono 3571 'left' contro 11428 'didn’t left'), sia un dataset bilanciato rispetto all’attributo target. Per il bilanciamento del dataset sono state effettuate prove con  SMOTE (Synthetic Minority Over-sampling Technique), random oversampling e random undersampling. Poiché non si è osservata una significativa variazione nei risultati, si è deciso di costruire il dataset bilanciato con random undersampling. In esso si ha lo stesso numero di \textit{left}=0 ("didn’t left") e di \textit{left}=1, per un totale di 7142 record.

\subsection{Generazione dei decision trees}
	Prima di procedere con la costruzione dei decision trees è stato necessario trasformare le variabili categoriche \textit{salary} e \textit{departments} in numeriche di tipo binario, in quanto il modello usato, fornito dalla libreria python Scikit-learn, funziona con valori numerici e permette di effettuare solo binary splits. Per \textit{salary}, ad esempio, sono stati ottenuti i tre attributi \textit{salary\_val\_high}, \textit{salary\_val\_low}, \textit{salary\_val\_medium}, ognuno dei quali può assumere valore 0 o 1.$\newline$
	Per la generazione e la valutazione dei diversi decision trees sono stati usati il metodo holdout, che usa due terzi del dataset per il training e un terzo per il testing, e la cross validation, suddividendo il dataset in dieci parti di cui alternativamente nove vengono usate come training set e una come test set.$\newline$
	Sia per il dataset sbilanciato che per quello bilanciato sono stati generati diversi decision trees ottenuti variando i parametri riguardanti la profondità dell’albero, il minimo numero di record necessari per lo splitting di un nodo, il numero massimo e il tipo di features considerate per la costruzione dell’albero e il criterio usato per misurare la qualità di uno split, ovvero gini o entropy.$\newline$
	Dai diversi alberi generati si è potuto notare come gini ed entropy dessero risultati molto simili tra loro, alcune volte leggermente migliori per gini e altre usando entropy. In alcuni casi i risultati erano leggermente più significativi se venivano escluse dalla fase di apprendimento alcune features, ovvero quelle riguardanti il dipartimento di appartenenza di ogni impiegato. È stato deciso, dunque, di usare gini come misura della qualità degli splits e di escludere dalle features quelle riguardanti il dipartimento di appartenenza di ogni impiegato, mantenendo invece, \textit{satisfaction\_level}, \textit{last\_evaluation}, \textit{number\_project}, \textit{promotion\_last\_5years}, \textit{average\_daily\_hours}, \textit{time\_spent\_company}, \textit{work\_accident}, \textit{salary\_val\_high}, \textit{salary\_val\_low}, \textit{salary\_val\_medium}, le quali tra l’altro, erano risultate già da analisi precedenti come il k-means legate alla decisione di un impiegato di lasciare la compagnia.
	
\subsubsection{Validazione dei decision trees tramite test e training set}
	Riguardo al dataset non bilanciato, osservando in particolare le misure di \textit{accuracy}, \textit{precision}, \textit{recall} e \textit{f1-measure} ottenute attraverso una valutazione holdout per i diversi alberi generati, si può notare che si parte fin da subito, anche con modelli di profondità bassa (2 o 3) con valori di accuratezza elevati, tra l’85\% e il 95\% sia per training che per test set. $\newline$
	Per quanto riguarda la \textit{precision} e la \textit{recall}, la selezione delle features da usare nell’apprendimento del modello ha permesso in qualche caso di colmare le differenze tra i valori per \textit{left}=0 e \textit{left}=1 ottenuti con la valutazione sul test set. Senza la selezione delle features che ha portato all’eliminazione di quelle che riguardano il dipartimento di appartenenza, infatti, ad esempio, un decision tree di profondità 3 presenta sul test set una \textit{precision} del 98\% per \textit{left}=0 e del 77\% per \textit{left}=1 e una \textit{recall} del 92\% per \textit{left}=0 e del 94\% per \textit{left}=1. La differenza notevole tra il valore di \textit{precision} per \textit{left}=0 e quello \textit{left}=1 è data proprio dal fatto che il dataset è sbilanciato verso coloro che non hanno lasciato il lavoro, quindi per \textit{left}=0. Sempre per un albero di profondità 3, selezionando solo dieci features ed eliminando quelle relative al dipartimento di appartenenza, si riesce a far diminuire la differenza tra \textit{precision} per \textit{left}=0, che rimane 98\%, e quella per \textit{left}=1, che sale all’88\%, mentre i valori della \textit{recall} si stabilizzano al 96\% per \textit{left}=0 e 92\% per \textit{left}=1. Si registra in generale un aumento del valore di \textit{f1-measure} sia per \textit{left}=0 che per \textit{left}=1. $\newline$
	Sempre sul dataset sbilanciato, inoltre, è possibile notare che la differenza tra \textit{precision} per \textit{left}=0 e per \textit{left}=1 diminuisce non solo attraverso la selezione delle features, ma anche aumentando la profondità dell’albero. In questo ultimo caso, è necessario tuttavia, controllare sempre che non si tratti di overfitting. $\newline$
	Per quanto riguarda le misure di \textit{accuracy}, \textit{precision}, \textit{recall} e \textit{f1-measure} ottenute a partire dal dataset bilanciato utilizzando sempre una valutazione holdout e selezionando le dieci features indicate in precedenza (4.1), invece, si può notare fin da subito che a una diminuzione non eccessiva dell’accuratezza dei modelli corrisponde, già a partire dai decision trees con profondità più bassa, un maggiore equilibrio dei valori della \textit{precision} per \textit{left}=0 e per \textit{left}=1. Per un decision tree di profondità 3, ad esempio, si ha un’accuratezza sia sul training che sul test del 92\%, una \textit{precision} sul test del 93\% per \textit{left}=0 e del 91\% per \textit{left}=1 e una \textit{recall} del 91\% per \textit{left}=0 e del 93\% per \textit{left}=1. $\newline$
	I valori di accuratezza ottenuti sia per il training che per il test attraverso cross validation sono molto simili e rispecchiano quelli forniti da holdout sia per il dataset non bilanciato, sia per quello bilanciato.
	
\subsubsection{Decision tree su dataset non bilanciato}
	I valori di \textit{accuracy} sul test set riguardanti il decision tree selezionato per il dataset non bilanciato sono rispettivamente 98\% con validazione holdout e 98\% con cross validation.$\newline$
	La seguente tabella mostra i valori di \textit{precision}, \textit{recall} e \textit{f1-measure} relativi al test set per l’attributo target \textit{left}=0 e \textit{left}=1 ottenuti con holdout.
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			\textbf{ValidationTarget} & \textbf{left} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-measure} & \textbf{Support} \\ \hline
			Holdout & 0 & 98\% & 99\% & 98\% & 3818 \\ \hline
			& 1 & 98\% & 92\% & 95\% & 1132 \\ \hline
		\end{tabular}
		\caption{Statistiche Decision tree con dataset non bilanciato.}
	\end{table}\vspace{-0.3cm}$\newline$
	Anche se il valore dell’\textit{accuracy} risulta molto alto sul training set (98\%) e potrebbe far pensare che si tratti di overfitting, costruendo un grafico che mostra gli errori del training e del test set a confronto all’aumentare della profondità dell’albero, tale fenomeno è stato escluso in quanto non si registra un aumento degli errori sul test al diminuire di quelli sul training per il modello preso in considerazione. $\newline$
	È possibile notare, come evidenziato anche in precedenza (4.1.1) che pur trattandosi di un dataset sbilanciato verso \textit{left}=0 sono stati raggiunti dei valori di \textit{precision} e \textit{recall} elevati anche per \textit{left}=1.$\newline$
	Il modello usato individua due principali categorie di impiegati che lasciano il lavoro. Da un lato vi sono 1025 impiegati che hanno un livello di soddisfazione, un numero di progetti, una valutazione e un numero di ore lavorative giornaliere inferiori rispetto alla media (1.2). Questi impiegati, infatti, hanno un livello di soddisfazione minore o uguale a 0.5, un numero di progetti minore o uguale a 2.5, una valutazione compresa tra 0.4 e 0.6 e un numero di ore lavorative giornaliere compreso tra 5.8 e 7.5. Dall'altro vi sono 581 impiegati che hanno valutazione, numero di ore lavorative giornaliere, numero di anni trascorsi nella compagnia e livello di soddisfazione superiori rispetto alla media e numero di progetti vicino alla media (1.2) o superiore ad essa. Essi hanno, infatti, valutazione maggiore di 0.8, numero di ore lavorative maggiore di 10, numero di anni trascorsi nella compagnia compreso tra 4.5 e 6.5, soddisfazione maggiore di 0.7 e numero di progetti maggiore di 3.5.

\subsubsection{Decision tree su dataset bilanciato}
	I valori di \textit{accuracy} sul test set riguardanti il decision tree selezionato per il dataset bilanciato sono rispettivamente 94\% con validazione holdout e 94\% con cross validation.
	La seguente tabella mostra i valori di \textit{precision}, \textit{recall} e \textit{f1-measure} relativi al test set per l’attributo target \textit{left}=0 e \textit{left}=1 ottenuti con holdout.
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			\textbf{ValidationTarget} & \textbf{left} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-measure} & \textbf{Support} \\ \hline
			Holdout & 0 & 94\% & 94\% & 94\% & 1171 \\ \hline
			& 1 & 94\% & 94\% & 94\% & 1186 \\ \hline
		\end{tabular}
		\caption{Statistiche Decision tree con dataset bilanciato.}
	\end{table}\vspace{-0.3cm}$\newline$
	I valori di \textit{accuracy}, \textit{precision}, \textit{recall} e \textit{f1-measure} risultano più bassi di quelli ottenuti sul dataset non bilanciato, ma questo modello permette di raggiungere un equilibrio tra \textit{precision} e \textit{recall} per \textit{left}=0 e \textit{left}=1, infatti rispetto al modello precedente, si abbassa la \textit{recall} per \textit{left}=0 ma si alza quella per \textit{left}=1. $\newline$
	Anche in questo caso, il valore di \textit{accuracy} elevato sul training set (95\%) potrebbe far pensare che vi sia overfitting, ma il fenomeno è stato escluso in quanto non si registra un aumento degli errori sul test al diminuire di quelli sul training per il modello preso in considerazione. $\newline$
	Anche questo modello individua due principali categorie di impiegati che lasciano il lavoro, molto simili a quelle individuate dal modello allenato su dataset non bilanciato. Da un lato vi sono 1023 impiegati che hanno un livello di soddisfazione e un numero di progetti inferiori rispetto alla media (1.2), una valutazione e un numero di ore lavorative giornaliere che partono da valori inferiori rispetto alla media e un numero di anni trascorsi nella compagnia di poco al di sotto o al di sopra della media. Questi impiegati, infatti, hanno un livello di soddisfazione minore o uguale a 0.5, un numero di progetti minore o uguale a 2.5, una valutazione maggiore di 0.4, un numero di ore lavorative giornaliere maggiore di 5.8 e hanno trascorso nella compagnia da 2.5 a 4.5 anni. Dall’altro vi sono 595 impiegati che hanno valutazione, numero di ore lavorative giornaliere, numero di anni trascorsi nella compagnia e livello di soddisfazione superiori rispetto alla media. Essi hanno, infatti, valutazione maggiore di 0.8, numero di ore lavorative maggiore di 9.9, numero di anni trascorsi nella compagnia compreso tra 4.5 e 6.5, soddisfazione maggiore di 0.7.


\subsection{Random Forest}
	Il secondo modello usato per la classificazione è Random Forest che combinato con RandomizedSearchCV (nome del metodo usato da python) permette di addestrare diversi decision trees usando per ognuno una combinazione di parametri tra quelli forniti e di restituire il modello che ha fornito i migliori risultati. $\newline$
	Anche in questo caso, prima di procedere con l’addestramento del modello è stato necessario trasformare le variabili categoriche in numeriche di tipo binario e si è scelto di escludere dalle features quelle riguardanti il dipartimento di appartenenza di ogni impiegato, mantenendo invece, \textit{satisfaction\_level}, \textit{last\_evaluation}, \textit{number\_project}, \textit{promotion\_last\_5years}, \textit{average\_daily\_hours}, \textit{time\_spent\_company}, \textit{work\_accident}, \textit{salary\_val\_high}, \textit{salary\_val\_low}, \textit{salary\_val\_medium}.$\newline$
	La valutazione dei modelli restituiti dalla ricerca è stata fatta con holdout e cross validation.

\subsubsection{Validazione tramite test e training set su dataset non bilanciato e bilanciato}
	I valori di \textit{accuracy} sul test set riguardanti il decision tree selezionato attraverso Random Forest per il dataset sbilanciato sono rispettivamente 98\% con validazione holdout e 98\% con cross validation.$\newline$
	La seguente tabella mostra i valori di \textit{precision}, \textit{recall} e \textit{f1-measure} relativi al test set per l’attributo target \textit{left}=0 e \textit{left}=1 ottenuti con holdout.
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			\textbf{ValidationTarget} & \textbf{left} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-measure} & \textbf{Support} \\ \hline
			Holdout & 0 & 98\% & 100\% & 99\% & 3818 \\ \hline
			& 1 & 99\% & 92\% & 95\% & 1132 \\ \hline
		\end{tabular}
		\caption{Statistiche Random Forest con dataset non bilanciato.}
	\end{table}\vspace{-0.3cm}$\newline$
	I risultati del modello selezionato non sono molto diversi da quelli ottenuti direttamente con decision tree (4.1.2).$\newline$
	I valori di \textit{accuracy} sul test set riguardanti il decision tree selezionato attraverso Random Forest per il dataset bilanciato sono rispettivamente 95\% con validazione holdout e 96\% con cross validation.$\newline$
	La seguente tabella mostra i valori di \textit{precision}, \textit{recall} e \textit{f1-measure} relativi al test set per l’attributo target \textit{left}=0 e \textit{left}=1 ottenuti con holdout.
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			\textbf{ValidationTarget} & \textbf{left} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-measure} & \textbf{Support} \\ \hline
			Holdout & 0 & 92\% & 99\% & 95\% & 1171 \\ \hline
			& 1 & 99\% & 92\% & 95\% & 1186 \\ \hline
		\end{tabular}
		\caption{Statistiche Random Forest con dataset bilanciato.}
	\end{table}\vspace{-0.3cm}$\newline$
	Rispetto ai risultati ottenuti con decision tree (4.1.3) si può notare, oltre che una lievissima crescita dell’accuratezza sul test (dal 94\% al 95\%), una crescita della \textit{precision} per \textit{left}=1 a cui corrisponde, tuttavia, la diminuzione di \textit{precision} per \textit{left}=0, mentre la \textit{recall} subisce un andamento opposto.

\subsection{Discussione sul miglior modello di predizione}
	Possiamo concludere che relativamente al tipo di modello da usare per la classificazione, per il dataset sbilanciato non si sono registrate significative variazioni nelle misure di valutazione con l’uso di Random Forest invece che di Decision tree. $\newline$
	Un lieve innalzamento dell’accuratezza si è, invece registrato con l’uso di Random Forest per il dataset bilanciato. A esso è corrisposto un aumento della \textit{precision} per \textit{left}=1.
	